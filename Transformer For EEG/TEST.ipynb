{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "import pyedflib\n",
    "\n",
    "def PhysioNetMIConvert(file_name,show_info=False):\n",
    "    '''\n",
    "    Parameters\n",
    "    ————————————————————————————————————————————————————\n",
    "        file_name :    str\n",
    "                    edf文件名\n",
    "\n",
    "    Return\n",
    "    ————————————————————————————————————————————————————\n",
    "        masterSet : 2D array (channels x nsamples)\n",
    "                    edf文件数据  \n",
    "                    第1个通道是时间戳\n",
    "                    第2个通道是标签\n",
    "                    第3-66个通道是电极通道\n",
    "    '''\n",
    "    \n",
    "\n",
    "    reader = pyedflib.EdfReader(file_name)\n",
    "    annotations = reader.readAnnotations()\n",
    "    end_time =  annotations[0][-1]+annotations[1][-1]\n",
    "    intervals = np.append(annotations[0],end_time)   #删除最后半秒的全零数据，将间隔点在末尾添加124.5标志\n",
    "    \n",
    "    timeArray = np.array([round(x,5) for x in np.arange(0,end_time,.00625)])\n",
    "    time_points = int(end_time*160)\n",
    "    timeArray = timeArray.reshape(time_points,1)   #一共124.5s，采样率160hz，共19920个数据点\n",
    "\n",
    "    codes = annotations[2]     #codes为事件标志位\n",
    "    codeArray = []             #codeArray为每一个数据点所代表的事件标志位\n",
    "    counter = 1     \n",
    "    for timeVal in timeArray:\n",
    "        if timeVal == end_time:\n",
    "            break   \n",
    "        elif timeVal / intervals[counter] == 1.0:\n",
    "            counter += 1\n",
    "\n",
    "        codeArray.append(codes[counter - 1])\n",
    "    \n",
    "\n",
    "    invertCodeArray = np.array(codeArray).reshape(time_points,1)\n",
    "    numSignals = reader.signals_in_file   #数据的通道数（电极数）\n",
    "    \n",
    "    signal_labels = reader.getSignalLabels()  #数据通道的标签（电极标签）\n",
    "\n",
    "    dataset = np.zeros((numSignals, reader.getNSamples()[0]))\n",
    "    for signal in np.arange(numSignals):\n",
    "        dataset[signal, :] = reader.readSignal(signal)\n",
    "\n",
    "    dataset = dataset[:,:time_points].transpose()\n",
    "\n",
    "\n",
    "    masterSet = np.concatenate((timeArray,invertCodeArray,dataset),axis=1).swapaxes(0,1)\n",
    "\n",
    "\n",
    "    if show_info:\n",
    "        print('annotations \\n',annotations)  \n",
    "        print('intervals values \\n',intervals)\n",
    "        print('codeArray value \\n',codeArray)\n",
    "        print('all channels number :',numSignals)\n",
    "        print('channels labels :',signal_labels)\n",
    "        print('all file samples :',reader.getNSamples()[0])\n",
    "        print('masterSet :',masterSet.shape)\n",
    "\n",
    "    return masterSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/train/S001/S001R03.edf'\n",
    "\n",
    "'''\n",
    "reader = pyedflib.EdfReader(file_name)\n",
    "annotations = reader.readAnnotations()\n",
    "print(annotations)\n",
    "'''\n",
    "\n",
    "raw_data = PhysioNetMIConvert(file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.0', '0.00625', '0.0125', ..., '124.48125', '124.4875',\n",
       "        '124.49375'],\n",
       "       ['T0', 'T0', 'T0', ..., 'T1', 'T1', 'T1'],\n",
       "       ['-57.0', '-49.0', '-55.0', ..., '23.0', '38.0', '50.0'],\n",
       "       ...,\n",
       "       ['-56.0', '-70.0', '-77.0', ..., '97.0', '81.0', '32.0'],\n",
       "       ['-124.0', '-149.0', '-153.0', ..., '156.0', '140.0', '78.0'],\n",
       "       ['-28.0', '-40.0', '-37.0', ..., '75.0', '66.0', '16.0']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def extractData(raw_data,time_range=[0,4],sample_rate=160):\n",
    "    '''\n",
    "        对从PhysioNetMIConvert函数中取出的数进行信号拆解,输出T1和T2类别的数据\n",
    "    \n",
    "    Parameters\n",
    "    ——————————————————————————————————————————————\n",
    "        raw_data : 2D array (channels x nsamples)\n",
    "                    PhysioNetMIConvert函数中提取的原始数据\n",
    "        time_range : list \n",
    "                    取出数据段的起始点和终止点  ,单位s\n",
    "        sample_rate : float\n",
    "                    数据的采样率\n",
    "\n",
    "    Returns\n",
    "    ——————————————————————————————————————————————\n",
    "        retval : dict\n",
    "                T1和T2数据   格式为 3D array (ntrials x nchannels x nsamples)\n",
    "    '''\n",
    "\n",
    "\n",
    "    start = sample_rate * time_range[0]\n",
    "    end = sample_rate * time_range[1]\n",
    "    left_data = []\n",
    "    idx = 0\n",
    "    data = raw_data\n",
    "    while data.shape[1]>0: \n",
    "        marker = data[1,:].tolist()\n",
    "        if 'T1' not in marker:\n",
    "            break\n",
    "        idx = marker.index('T1')\n",
    "        #print('idx : ',idx,'   data shape : ',data.shape)\n",
    "        l_data = []\n",
    "        i = idx \n",
    "        while marker[i] == 'T1':\n",
    "            l_data.append(data[2:,i])\n",
    "            i = i + 1\n",
    "            if i >= data.shape[1]:\n",
    "                break\n",
    "        idx = i\n",
    "        data = data[:,idx:]\n",
    "        if len(l_data) >= int(end-start) : \n",
    "            left_data.append(l_data[start:end])\n",
    "\n",
    "    left_data_np = np.array(left_data,dtype=np.float32)\n",
    "    left_data_np = left_data_np.swapaxes(1,2)\n",
    "\n",
    "\n",
    "    right_data = []\n",
    "    idx = 0\n",
    "    data = raw_data\n",
    "    while data.shape[1]>0: \n",
    "        marker = data[1,:].tolist()\n",
    "        if 'T2' not in marker:\n",
    "            break\n",
    "        idx = marker.index('T2')\n",
    "        \n",
    "        r_data = []\n",
    "        i = idx \n",
    "        while marker[i] == 'T2':\n",
    "            r_data.append(data[2:,i])\n",
    "            i = i + 1\n",
    "            if i >= data.shape[1]:\n",
    "                break\n",
    "        idx = i\n",
    "        data = data[:,idx:]\n",
    "        if len(r_data) >= int(end-start) :\n",
    "            right_data.append(r_data[start:end])\n",
    "\n",
    "    right_data_np = np.array(right_data,dtype=np.float32)\n",
    "    right_data_np = right_data_np.swapaxes(1,2)\n",
    "\n",
    "\n",
    "    retval = {'T1':left_data_np,'T2':right_data_np}\n",
    "\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def concatenateAllData(base_dir):\n",
    "    '''\n",
    "        获取全部被试数据  剔除第88,第92和第100个数据异常的被试\n",
    "    Parameters\n",
    "    ————————————————————————————————————————————————\n",
    "    base_dir : str\n",
    "                基础数据集文件夹\n",
    "    \n",
    "    Returns\n",
    "    ————————————————————————————————————————————————\n",
    "    all_left : List \n",
    "            左手 的全部run的数据 all_left[n]表示第n个被试数据  3D array (ntrials x nchannels x nsamples) \n",
    "    all_right : List\n",
    "    all_fist : List\n",
    "    all_feet : List\n",
    "    \n",
    "    '''\n",
    "    left_right_runs = [3,4,7,8,11,12]\n",
    "    fist_feet_runs = [5,6,9,10,13,14]\n",
    "\n",
    "    all_left = []\n",
    "    all_right = []\n",
    "    all_fist = []\n",
    "    all_feet = []\n",
    "    for i in tqdm(range(109)):\n",
    "        \n",
    "        nsub = i + 1\n",
    "        #print(nsub)\n",
    "        if nsub == 92 or nsub==100 or nsub==88:\n",
    "\n",
    "            continue\n",
    "\n",
    "        for nrun in range(3,15):\n",
    "            \n",
    "            sub_file_name = base_dir + '/S' + '{:03d}'.format(nsub) + '/S' +  '{:03d}'.format(nsub) + 'R' + '{:02d}'.format(nrun) + '.edf'\n",
    "            #print(sub_file_name)\n",
    "            data = extractData(PhysioNetMIConvert(sub_file_name))\n",
    "            if nrun in left_right_runs:\n",
    "                if nrun == 3:\n",
    "                    left = data['T1']\n",
    "                    right = data['T2']\n",
    "                else:\n",
    "                    left = np.concatenate((left,data['T1']))\n",
    "                    right = np.concatenate((right,data['T2']))\n",
    "            elif nrun in fist_feet_runs:\n",
    "                if nrun == 5:\n",
    "                    fist = data['T1']\n",
    "                    feet = data['T2']\n",
    "                else:\n",
    "                    fist = np.concatenate((fist,data['T1']))\n",
    "                    feet = np.concatenate((feet,data['T2']))\n",
    "\n",
    "        all_left.append(left)\n",
    "        all_right.append(right)\n",
    "        all_fist.append(fist)\n",
    "        all_feet.append(feet) \n",
    "        \n",
    "    print(len(all_left),len(all_right),len(all_fist),len(all_feet))\n",
    "\n",
    "    return all_left,all_right,all_fist,all_feet                 \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [13:16<00:00,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 106 106 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "left_data,right_data,fist_data,feet_data = concatenateAllData('data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ANACONDA\\envs\\ML_py38_CU\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject : 0  , mean ACC : 78.519 %\n",
      "subject : 1  , mean ACC : 68.889 %\n",
      "subject : 2  , mean ACC : 63.704 %\n",
      "subject : 3  , mean ACC : 68.889 %\n",
      "subject : 4  , mean ACC : 54.815 %\n",
      "subject : 5  , mean ACC : 55.556 %\n",
      "subject : 6  , mean ACC : 99.259 %\n",
      "subject : 7  , mean ACC : 46.667 %\n",
      "subject : 8  , mean ACC : 44.444 %\n",
      "subject : 9  , mean ACC : 68.148 %\n",
      "subject : 10  , mean ACC : 68.889 %\n",
      "subject : 11  , mean ACC : 55.556 %\n",
      "subject : 12  , mean ACC : 65.926 %\n",
      "subject : 13  , mean ACC : 59.259 %\n",
      "subject : 14  , mean ACC : 66.667 %\n",
      "subject : 15  , mean ACC : 48.889 %\n",
      "subject : 16  , mean ACC : 51.111 %\n",
      "subject : 17  , mean ACC : 47.407 %\n",
      "subject : 18  , mean ACC : 67.407 %\n",
      "subject : 19  , mean ACC : 65.926 %\n",
      "subject : 20  , mean ACC : 65.926 %\n",
      "subject : 21  , mean ACC : 85.185 %\n",
      "subject : 22  , mean ACC : 57.778 %\n",
      "subject : 23  , mean ACC : 62.222 %\n",
      "subject : 24  , mean ACC : 67.407 %\n",
      "subject : 25  , mean ACC : 80.741 %\n",
      "subject : 26  , mean ACC : 57.037 %\n",
      "subject : 27  , mean ACC : 50.370 %\n",
      "subject : 28  , mean ACC : 87.407 %\n",
      "subject : 29  , mean ACC : 57.037 %\n",
      "subject : 30  , mean ACC : 85.185 %\n",
      "subject : 31  , mean ACC : 95.556 %\n",
      "subject : 32  , mean ACC : 67.407 %\n",
      "subject : 33  , mean ACC : 86.667 %\n",
      "subject : 34  , mean ACC : 78.519 %\n",
      "subject : 35  , mean ACC : 48.889 %\n",
      "subject : 36  , mean ACC : 46.667 %\n",
      "subject : 37  , mean ACC : 55.556 %\n",
      "subject : 38  , mean ACC : 54.074 %\n",
      "subject : 39  , mean ACC : 82.222 %\n",
      "subject : 40  , mean ACC : 50.370 %\n",
      "subject : 41  , mean ACC : 94.815 %\n",
      "subject : 42  , mean ACC : 64.444 %\n",
      "subject : 43  , mean ACC : 57.037 %\n",
      "subject : 44  , mean ACC : 57.037 %\n",
      "subject : 45  , mean ACC : 75.556 %\n",
      "subject : 46  , mean ACC : 52.593 %\n",
      "subject : 47  , mean ACC : 90.370 %\n",
      "subject : 48  , mean ACC : 87.407 %\n",
      "subject : 49  , mean ACC : 56.296 %\n",
      "subject : 50  , mean ACC : 68.889 %\n",
      "subject : 51  , mean ACC : 80.000 %\n",
      "subject : 52  , mean ACC : 92.593 %\n",
      "subject : 53  , mean ACC : 86.667 %\n",
      "subject : 54  , mean ACC : 81.481 %\n",
      "subject : 55  , mean ACC : 94.815 %\n",
      "subject : 56  , mean ACC : 62.222 %\n",
      "subject : 57  , mean ACC : 55.556 %\n",
      "subject : 58  , mean ACC : 45.926 %\n",
      "subject : 59  , mean ACC : 75.556 %\n",
      "subject : 60  , mean ACC : 70.370 %\n",
      "subject : 61  , mean ACC : 77.778 %\n",
      "subject : 62  , mean ACC : 40.000 %\n",
      "subject : 63  , mean ACC : 68.148 %\n",
      "subject : 64  , mean ACC : 57.037 %\n",
      "subject : 65  , mean ACC : 59.259 %\n",
      "subject : 66  , mean ACC : 53.333 %\n",
      "subject : 67  , mean ACC : 52.593 %\n",
      "subject : 68  , mean ACC : 64.444 %\n",
      "subject : 69  , mean ACC : 82.963 %\n",
      "subject : 70  , mean ACC : 77.037 %\n",
      "subject : 71  , mean ACC : 81.481 %\n",
      "subject : 72  , mean ACC : 50.370 %\n",
      "subject : 73  , mean ACC : 54.815 %\n",
      "subject : 74  , mean ACC : 57.037 %\n",
      "subject : 75  , mean ACC : 62.222 %\n",
      "subject : 76  , mean ACC : 45.926 %\n",
      "subject : 77  , mean ACC : 38.519 %\n",
      "subject : 78  , mean ACC : 56.296 %\n",
      "subject : 79  , mean ACC : 60.741 %\n",
      "subject : 80  , mean ACC : 75.556 %\n",
      "subject : 81  , mean ACC : 65.185 %\n",
      "subject : 82  , mean ACC : 74.815 %\n",
      "subject : 83  , mean ACC : 48.148 %\n",
      "subject : 84  , mean ACC : 72.593 %\n",
      "subject : 85  , mean ACC : 60.741 %\n",
      "subject : 86  , mean ACC : 47.407 %\n",
      "subject : 87  , mean ACC : 58.667 %\n",
      "subject : 88  , mean ACC : 61.481 %\n",
      "subject : 89  , mean ACC : 71.111 %\n",
      "subject : 90  , mean ACC : 76.296 %\n",
      "subject : 91  , mean ACC : 87.407 %\n",
      "subject : 92  , mean ACC : 51.852 %\n",
      "subject : 93  , mean ACC : 59.259 %\n",
      "subject : 94  , mean ACC : 54.815 %\n",
      "subject : 95  , mean ACC : 54.815 %\n",
      "subject : 96  , mean ACC : 54.815 %\n",
      "subject : 97  , mean ACC : 49.630 %\n",
      "subject : 98  , mean ACC : 65.926 %\n",
      "subject : 99  , mean ACC : 54.815 %\n",
      "subject : 100  , mean ACC : 73.333 %\n",
      "subject : 101  , mean ACC : 76.296 %\n",
      "subject : 102  , mean ACC : 40.741 %\n",
      "subject : 103  , mean ACC : 57.778 %\n",
      "subject : 104  , mean ACC : 68.889 %\n",
      "subject : 105  , mean ACC : 57.778 %\n",
      "all sub mean acc : 64.886 % \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import models.CSP as CSP\n",
    "\n",
    "ALL_ACC = []\n",
    "for i in range(len(left_data)):\n",
    "    data = np.concatenate((left_data[i],right_data[i]),axis=0)\n",
    "    label = np.concatenate((np.zeros((left_data[i].shape[0],)),np.ones((right_data[i].shape[0],))))\n",
    "\n",
    "    data_process = CSP.cheb_bandpass_filter(data,8,30,160)\n",
    "\n",
    "    csp_num = 5\n",
    "\n",
    "    #print(data_process.shape)\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, train_size=0.7, random_state=1)\n",
    "\n",
    "\n",
    "    from sklearn import svm\n",
    "\n",
    "    ACC = []\n",
    "\n",
    "\n",
    "\n",
    "    for train_idx,test_idx in sss.split(data,label):\n",
    "        \n",
    "        X_train = data_process[train_idx,:,:]\n",
    "        y_train = label[train_idx]\n",
    "        X_test = data_process[test_idx,:,:]\n",
    "        y_test = label[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "        csp_mat = CSP.cal_csp(X_train[y_train==0],X_train[y_train==1],num=csp_num)\n",
    "        F_train =  CSP.cal_feature(csp_mat,X_train,num=csp_num)\n",
    "        F_test = CSP.cal_feature(csp_mat,X_test,num=csp_num)\n",
    "\n",
    "        svm_clf = svm.SVC(C=1, kernel='linear', probability=False)\n",
    "        svm_clf.fit(F_train,y_train)\n",
    "\n",
    "        pred = svm_clf.predict(F_test)\n",
    "\n",
    "        p = np.array(pred)\n",
    "        accuracy = np.sum(p == y_test) / p.shape[0]\n",
    "        ACC.append(accuracy)\n",
    "\n",
    "\n",
    "    #print('ALL ACC :',ACC)\n",
    "    ALL_ACC.append(np.mean(ACC))\n",
    "    print(\"subject : %d  , mean ACC : %.3f %%\" % (i,np.mean(ACC)*100))\n",
    "print('all sub mean acc : %.3f %% '%(np.mean(ALL_ACC)*100))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allSubLeftData shape :  (4800, 64, 640)\n",
      "allSubRightData shape :  (4744, 64, 640)\n",
      "allSubFistData shape :  (4751, 64, 640)\n",
      "allFeetLeftData shape :  (4843, 64, 640)\n"
     ]
    }
   ],
   "source": [
    "for nsub in range(len(left_data)):\n",
    "    if nsub == 0:\n",
    "        allSubLeftData = left_data[nsub]\n",
    "    else:\n",
    "        allSubLeftData = np.concatenate((allSubLeftData,left_data[nsub]),axis=0)\n",
    "print('allSubLeftData shape : ',allSubLeftData.shape)\n",
    "\n",
    "for nsub in range(len(right_data)):\n",
    "    if nsub == 0:\n",
    "        allSubRightData = right_data[nsub]\n",
    "    else:\n",
    "        allSubRightData = np.concatenate((allSubRightData,right_data[nsub]),axis=0)\n",
    "print('allSubRightData shape : ',allSubRightData.shape)\n",
    "\n",
    "for nsub in range(len(fist_data)):\n",
    "    if nsub == 0:\n",
    "        allSubFistData = fist_data[nsub]\n",
    "    else:\n",
    "        allSubFistData = np.concatenate((allSubFistData,fist_data[nsub]),axis=0)\n",
    "print('allSubFistData shape : ',allSubFistData.shape)\n",
    "\n",
    "for nsub in range(len(feet_data)):\n",
    "    if nsub == 0:\n",
    "        allFeetLeftData = feet_data[nsub]\n",
    "    else:\n",
    "        allFeetLeftData = np.concatenate((allSubLeftData,feet_data[nsub]),axis=0)\n",
    "print('allFeetLeftData shape : ',allFeetLeftData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [11 19 20 21 22 23]]\n",
      "---------------\n",
      "[ 2.5         8.5        14.5        19.33333333]\n",
      "[1.70782513 1.70782513 1.70782513 3.94405319]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(24).reshape(4,6)\n",
    "x[3,0] = 11\n",
    "print(x)\n",
    "print('---------------')\n",
    "print(np.mean(x,axis=1))\n",
    "print(np.std(x,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,6) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\00_BCI_algorithm\\02_co_new\\80_transformer\\CNN_Transformer\\TEST.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/00_BCI_algorithm/02_co_new/80_transformer/CNN_Transformer/TEST.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m-\u001b[39;49m np\u001b[39m.\u001b[39;49mmean(x,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,6) (4,) "
     ]
    }
   ],
   "source": [
    "u = np.mean(x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML_py38_CU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ac08be1dbb30f12e419b49c075d468e9c858b2193977f79fe37129ec4d1135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
