{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 2\n",
      "electroencephalography (EEG), functional magnetic resonance imaging (fMRI), magnetoen-\n",
      "cephalography (MEG), and near-infrared spectroscopy (NIRS) [2, 3]. However, non-invasive\n",
      "BMI through EEG signal collecting through electrodes placed on the scalp has been a popu-\n",
      "lar choice due to its ﬁne temporal resolution, low cost, and user-friendly communication with\n",
      "other electronic devices. Compared with other types of brain signals, EEG has some distinct\n",
      "characteristics such as uniqueness, non-linearity, and non-stationary behaviors which vary with\n",
      "the human brain and the mental state of the particular subjects [10]. Additionally, due to the\n",
      "presence of noise from diﬀerent muscle artifacts, it poses a challenge to eﬀectively improve the\n",
      "signal-to-noise ratio (SNR) to enhance accuracy in subject classiﬁcation. Thus, the feature\n",
      "extraction and classiﬁcation of EEG signals is an important aspect of designing a robust BMI\n",
      "system. ThecommonlyusedEEGsignalsincludemotorimagery(MI)relatedmu/betarhythm\n",
      "(de)synchronization, event-related P300 potentials, and steady-state visually evoked potentials\n",
      "(SSVEPs) [11, 12]. Among these, MI is the most popular in various EEG-based BCI applica-\n",
      "tions [2, 3]. The general workﬂow of a typical EEG-based MI BCI system is shown in Fig.1\n",
      "which generally consist of four phases including brain signal acquisition, feature extraction,\n",
      "feature classiﬁcation, and device control interface. For feature extraction in time-frequency\n",
      "spectrum, wavelet [13] or short-time Fourier-transformation (STFT) [14] have been utilized.\n",
      "Due to the limitation of feature extraction in the same frequency band, the classiﬁcation accu-\n",
      "racy may fall for diﬀerent subjects. To overcome this, wavelet packet decomposition (WPD)\n",
      "and dynamic frequency feature selection (DFFS) [15] have been employed to obtain better\n",
      "time-frequency features for each subject [16]. However, the procedure is time-consuming and\n",
      "can notbe generalized. Inregard tofeature extractionof EEG signalin spacedomain, common\n",
      "spatial pattern (CSP) [17], ﬁlter bank CSP [18] have shown to be eﬀective in improving accu-\n",
      "racy, however, the performance depends on a speciﬁc frequency band and does not consider\n",
      "full time-domain feature extraction from diﬀerent subjects.\n",
      "With the advancement of deep learning (DL) in recent years, it illustrates superior per-\n",
      "formance in MI-BCI classiﬁcation compared to traditional ML methodologies [14] due to the\n",
      "capability of adapting non-linear and non-stationary signals and extracting important feature\n",
      "information [19] from EEG signal automatically. In this regard, there are several studies have\n",
      "been geared towards the EEG signal classiﬁcation employing DL, in particular, convolutional\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 1\n",
      "A CNN model with feature integration for MI EEG subject\n",
      "classiﬁcation in BMI\n",
      "Arunabha M. Roy1∗\n",
      "1∗University of Michigan, Aerospace Engineering, Ann Arbor, MI 48109, U.S.A.\n",
      "Abstract\n",
      "Objective. Electroencephalogram (EEG) based motor imagery (MI) classiﬁcation is an im-\n",
      "portant aspect in brain-machine interfaces (BMIs) which bridges between neural system and\n",
      "computer devices decoding brain signals into recognizable machine commands. However, the\n",
      "MI classiﬁcation task is challenging due to inherent complex properties, inter-subject variabil-\n",
      "ity, and low signal-to-noise ratio (SNR) of EEG signals. To overcome the above-mentioned\n",
      "issues, the current work proposes an eﬃcient multi-scale convolutional neural network (MS-\n",
      "CNN). Approach. In the framework, discriminant user-speciﬁc features have been extracted\n",
      "and integrated to improve the accuracy and performance of the CNN classiﬁer. Additionally,\n",
      "diﬀerent data augmentation methods have been implemented to further improve the accuracy\n",
      "and robustness of the model. Main results. The model achieves an average classiﬁcation ac-\n",
      "curacy of 93.74% and Cohen’s kappa-coeﬃcient of 0.92 on the BCI competition IV2b dataset\n",
      "outperforming several baseline and current state-of-the-art EEG-based MI classiﬁcation mod-\n",
      "els. Signiﬁcance. The proposed algorithm eﬀectively addresses the shortcoming of existing\n",
      "CNN-based EEG-MI classiﬁcation models and signiﬁcantly improves the classiﬁcation accu-\n",
      "racy.\n",
      "1. Introduction :\n",
      "Brain–computer interfaces (BCI) or brain-machine interface (BMI) enable a direct commu-\n",
      "nication between the brain and external devices [1, 2, 3] which allows rehabilitation of neu-\n",
      "romotor disorders [4], robotic control [5, 6, 7], speech communication [8, 9] etc. In general,\n",
      "BMIs can be invasive, non-invasive or synthetic telepathy [2]. Non-invasive method includes\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 2\n",
      "electroencephalography (EEG), functional magnetic resonance imaging (fMRI), magnetoen-\n",
      "cephalography (MEG), and near-infrared spectroscopy (NIRS) [2, 3]. However, non-invasive\n",
      "BMI through EEG signal collecting through electrodes placed on the scalp has been a popu-\n",
      "lar choice due to its ﬁne temporal resolution, low cost, and user-friendly communication with\n",
      "other electronic devices. Compared with other types of brain signals, EEG has some distinct\n",
      "characteristics such as uniqueness, non-linearity, and non-stationary behaviors which vary with\n",
      "the human brain and the mental state of the particular subjects [10]. Additionally, due to the\n",
      "presence of noise from diﬀerent muscle artifacts, it poses a challenge to eﬀectively improve the\n",
      "signal-to-noise ratio (SNR) to enhance accuracy in subject classiﬁcation. Thus, the feature\n",
      "extraction and classiﬁcation of EEG signals is an important aspect of designing a robust BMI\n",
      "system. ThecommonlyusedEEGsignalsincludemotorimagery(MI)relatedmu/betarhythm\n",
      "(de)synchronization, event-related P300 potentials, and steady-state visually evoked potentials\n",
      "(SSVEPs) [11, 12]. Among these, MI is the most popular in various EEG-based BCI applica-\n",
      "tions [2, 3]. The general workﬂow of a typical EEG-based MI BCI system is shown in Fig.1\n",
      "which generally consist of four phases including brain signal acquisition, feature extraction,\n",
      "feature classiﬁcation, and device control interface. For feature extraction in time-frequency\n",
      "spectrum, wavelet [13] or short-time Fourier-transformation (STFT) [14] have been utilized.\n",
      "Due to the limitation of feature extraction in the same frequency band, the classiﬁcation accu-\n",
      "racy may fall for diﬀerent subjects. To overcome this, wavelet packet decomposition (WPD)\n",
      "and dynamic frequency feature selection (DFFS) [15] have been employed to obtain better\n",
      "time-frequency features for each subject [16]. However, the procedure is time-consuming and\n",
      "can notbe generalized. Inregard tofeature extractionof EEG signalin spacedomain, common\n",
      "spatial pattern (CSP) [17], ﬁlter bank CSP [18] have shown to be eﬀective in improving accu-\n",
      "racy, however, the performance depends on a speciﬁc frequency band and does not consider\n",
      "full time-domain feature extraction from diﬀerent subjects.\n",
      "With the advancement of deep learning (DL) in recent years, it illustrates superior per-\n",
      "formance in MI-BCI classiﬁcation compared to traditional ML methodologies [14] due to the\n",
      "capability of adapting non-linear and non-stationary signals and extracting important feature\n",
      "information [19] from EEG signal automatically. In this regard, there are several studies have\n",
      "been geared towards the EEG signal classiﬁcation employing DL, in particular, convolutional\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 3\n",
      "neural network (CNN) [14, 20, 21, 22, 23, 24, 25]. A DL model with the combination of CNN\n",
      "and stacked autoencoders (SAE) have been developed which demonstrated the improvement\n",
      "of recognition accuracy for EEG signal classiﬁcation [14]. In [23], an end-to-end CNN has been\n",
      "designedforeﬃcientMI-EEGsignalclassiﬁcation. Sometraditionalfeatureextractionmethod-\n",
      "ologies such as wavelet transform (WT) from time-frequency images have been incorporated in\n",
      "CNN for subject classiﬁcation [26]. A DNN Scheme based on restricted Boltzmann machines\n",
      "(RBM) for MI classiﬁcation has been proposed in [27]. In addition, EEGNet framework [28]\n",
      "based on compact CNN has been proposed for MI and P300 visual-evoked potentials which\n",
      "demonstrated improvement of classiﬁcation accuracy compared to the state-of-the-art meth-\n",
      "ods. Along similar line, a deep transfer CNN framework based on the VGG-16 CNN model\n",
      "pre-trained on the ImageNet and a target CNN model for MI EEG signal classiﬁcation has\n",
      "been proposed in [29]. Furthermore, a 1-D multi-scale CNN [30] based on conditional empirical\n",
      "modedecomposition(CEMD)hasbeendevelopedwhichcorrelatestheoriginalEEGsignaland\n",
      "intrinsic modal component (IMF) to encode event-related synchronization/de-synchronization\n",
      "(ERS/ERD) information between the channels achieving higher accuracy for EEG signals clas-\n",
      "siﬁcation. Additionally, a multiple bandwidth method with optimized CNN framework [31] has\n",
      "been designed for BMI classiﬁcation with EEG-fNIRS signals. More recently, a hybrid-scale\n",
      "CNN architecture [32] for EEG MI classiﬁcation has been proposed which demonstrates sig-\n",
      "niﬁcant improvement in classiﬁcation accuracy.\n",
      "Although, the CNN-based models have achieved better results, there are several issues\n",
      "which cause to hinder the accuracy and performance of the classiﬁer for EEG MI classiﬁcation.\n",
      "Firstly, most of the CNN-based models consider only a single convolution scale which is not\n",
      "suﬃcient to extract distinguishable features of several non-overlapping canonical frequency\n",
      "bands of EEG signal eﬃciently. Secondly, intrinsic feature extraction of the input signal\n",
      "is often ignored which limits CNN’s ability to learn more semantic features from the raw\n",
      "EEG data. Moreover, feature extraction has not been designed to fully integrate into the\n",
      "DL workﬂow which is the main bottleneck for the deployment of real-time BCI applications\n",
      "with high classiﬁcation accuracy. Thirdly, one of the common issues of CNN-based models is\n",
      "the lack of suﬃcient training data which restrain to achieve high classiﬁcation accuracy for\n",
      "EEG-based MI-BCI classiﬁer.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 4\n",
      "Brain Signal Acquisition Feature Extraction  Feature Classification  Electronics Device \n",
      "(raw EEG data + artifact filtering)   Control \n",
      "Figure 1: The general workﬂow of a typical EEG-based MI-BCI system consist of brain signal\n",
      "acquisition, feature extraction, feature classiﬁcation, and device control interface.\n",
      "In order to address the aforementioned challenges and shortcomings, an eﬃcient multi-scale\n",
      "convolutional neural network (MS-CNN) has been proposed for EEG-based MI classiﬁcation.\n",
      "In the model, a multi-scale convolution block (MSCB) with diﬀerent convolutional kernel sizes\n",
      "has been designed to extract the eﬀective features of EEG signals from multiple scales for\n",
      "four diﬀerent frequency bands δ, θ, α, and β from original EEG data for MI classiﬁcation.\n",
      "Moreover, important intrinsic and user-speciﬁc features including diﬀerential entropy (DE)\n",
      "and neural power spectra (NPS) characteristics have been extracted from the original EEG\n",
      "data and integrated into the proposed algorithm to improve the accuracy and performance of\n",
      "the model. Additionally, diﬀerent data augmentation (DA) methods such as Gaussian noise\n",
      "(GN), signal segmentation and recombination (S & R), window slicing (WS), and window\n",
      "wrapping (WW) have been employed to further improve the accuracy and robustness of the\n",
      "proposed classiﬁer by increasing training EEG data. It has been found that the current algo-\n",
      "rithm signiﬁcantly outperforms several baselines and the current state-of-the-art EEG-based\n",
      "MI classiﬁcation models with an average classiﬁcation accuracy of 93.74% on BCI Competition\n",
      "IV2b dataset. Current study provides an eﬀective and eﬃcient framework for designing high\n",
      "performance real-time MI-BCI system.\n",
      "2. Dataset and description of experimental method :\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 5\n",
      "Imagination of \n",
      "right hand \n",
      "movement\n",
      "Nasion\n",
      "+\n",
      "Imagination of left \n",
      "hand movement\n",
      "Cue Paus\n",
      "Fixation Cross Imagery Period e Time \n",
      "(s)\n",
      "0 1 2 3 4 5 6 7 8\n",
      "Without Feedback Sessions\n",
      "A1 A2\n",
      "Grey Smiley FeedbCaucek Period esuaP Time \n",
      "(s)\n",
      "Inion 0 1 2 3 4 5 6 7 8\n",
      "With Feedback Sessions\n",
      "(a) (b)\n",
      "Figure 2: (a) Schematics of electrodes positioning of C , C , and C in standardized inter-\n",
      "3 Z 4\n",
      "national 10-20 electrode system ; (b) timing scheme of each trial including ﬁrst two sessions\n",
      "(top) and remaining three sessions (bottom).\n",
      "In the present work, BCI competition IV 2b dataset [33] has been utilized to evaluate the\n",
      "eﬃciency and accuracy of the proposed MS-CNN model. The 2b datasets contain EEG data\n",
      "collected from nine healthy subjects. For each subject, the EEG signal data has been recorded\n",
      "and collected from three bipolar EEG channel electrodes with a sampling frequency of 250 Hz.\n",
      "These electrodes (i.e., C , C , and C ) have been positioned according to standardized inter-\n",
      "3 Z 4\n",
      "national 10-20 electrode system [34] as shown in Fig. 2-(a). In order to eliminate the power\n",
      "line signal noise, a band-pass ﬁlter allowing EEG signal frequency between 0.5 Hz and 100\n",
      "Hz with a notch ﬁlter at 50Hz was implemented. Additionally, the electrooculogram (EOG)\n",
      "has been recorded using three monopolar electrodes [35, 36]. In the dateset, two types of\n",
      "MI classiﬁcation tasks has been performed by each subject which include left (class 1) and\n",
      "right-hand movement (class 2) imagination. From the given dataset, there is a total of 5 ses-\n",
      "sions were considered for each of the subjects. For each subject case, the ﬁrst two sessions\n",
      "consisting of 120 trials were collected without feedback in EEG signal data. Whereas, the\n",
      "remaining three sessions of 160 trials were recorded with EEG feedback. The schematic of\n",
      "each trial and corresponding timing stamp has been depicted in Fig. 2-(b). For example,\n",
      "consider the ﬁrst two sessions, the successive events are as following order: at the start of each\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 6\n",
      "trial (i.e., t=0) a ﬁxation cross appears; followed by a cue in the form of an arrow at t=3\n",
      "s to t=4.25 s indicating two distinct MI tasks at once; ﬁnally, the subject performs left and\n",
      "right-hand movement imagination according to arrow direction from t=4 s to t=7 s [35, 36, 37].\n",
      "3. Proposed CNN model:\n",
      "In recent years, CNN has demonstrated signiﬁcant performance improvement outperforming\n",
      "traditional ML approaches [38] in various applications such as object detection and computer\n",
      "vision [39, 40]. The MI subject classiﬁcation from the raw EEG signal with high variability\n",
      "and non-stationary noise is a challenging task. In this regard, CNN can be an eﬀective method\n",
      "for extracting the most relevant features and learning the hierarchical representations of high\n",
      "dimensional EEG time series data. CNN is a feed-forward network that is usually comprised\n",
      "of the following components: input layer, convolution (Conv) layer, pooling (Pool) layer, fully\n",
      "connected (FC) layer, and output layer. Generally, the CNN network consists of alternating\n",
      "convolution and pooling layers for extracting features, and a fully connected layer at the end\n",
      "for ﬁnal classiﬁcation. Mathematically, the convolution process can be expressed as :\n",
      " \n",
      "(cid:88)\n",
      "Sd = f  Sd−1 ∗wd +bd (1)\n",
      "j i ij i\n",
      "i∈Mj\n",
      "Where Sd is the jth feature information in the dth Conv ; Sd−1 and bd are the ith feature map\n",
      "j i i\n",
      "and bias term corresponding to d−1th and dth Conv, respectively; wd represents connect-\n",
      "ij\n",
      "ing weight between ith feature of the d−1th layer and jth feature of the dth layer; ∗ denotes\n",
      "convolution operator; M represents input feature collection; f(•) represents the activation\n",
      "j\n",
      "function which can be hyperbolic tangent f(x) = tanh(x), sigmoid type f(x) = 1/(1+e−x),\n",
      "or rectiﬁed linear units (ReLU) f(x) = max(0,x) etc. The main functionality of pooling layer\n",
      "is to reduce the spatial size of the representation and the number of network parameters while\n",
      "preserving important and relevant features information. The fully connected layer at the end\n",
      "of the CNN transforms the high dimensional feature map obtained from the previous layer into\n",
      "1D array. Finally, it is connected to the Softmax layer to predict the classiﬁcation result. How-\n",
      "ever, in EEG signals, there are several non-overlapping canonical frequency bands corresponds\n",
      "to various distinct behavioral state[41, 42]. Each frequency pattern represents a qualitative\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 7\n",
      "Large :  λL   \n",
      "    \n",
      " \n",
      "       \n",
      " \n",
      "Kernel: 1×ΩL   \n",
      "       \n",
      "   Max Pool 1×ΩL \n",
      "       \n",
      "Input Signal   Medium :  λM      \n",
      "  \n",
      " \n",
      "       \n",
      "    \n",
      " \n",
      "  Kernel: 1×ΩM   \n",
      "          Max Pool 1×ΩM     C \n",
      "       \n",
      "Small  :  λS    \n",
      "     Concatenate \n",
      " \n",
      "               \n",
      " \n",
      "  \n",
      "Kernel: 1×ΩS   \n",
      "       \n",
      "   Max Pool 1×ΩS \n",
      "       \n",
      "  \n",
      "Max Pool: 1 ×ΩP  Conv: 1 ×ΩC \n",
      "               \n",
      "Figure 3: Generalized schematic of network structure for proposed multiscale convolution\n",
      "block (MSCB) consisting of three diﬀerent convolution scale: large (λ ), medium (λ ), and\n",
      "L M\n",
      "small (λ ) for multi-scale feature extraction.\n",
      "S\n",
      "assessment of awareness during MI tasks. The low frequency δ- bands (1-4 HZ) was found\n",
      "to carry signiﬁcant class-related information [2, 43, 44]. Additionally, in movement-related\n",
      "MI-BCI systems, α (8-13 HZ)and β (13-30) rhythms are important due to their high temporal\n",
      "resolution [45]. An increase and decrease of power spectrum in the β and α- bands results\n",
      "in event-related synchronization (ERS) and event-related desynchronization (ERD), respec-\n",
      "tively [46, 47]. Recently, it has been revealed that θ-band (4-8 Hz) signiﬁcantly diﬀers between\n",
      "the left/right-hand MI tasks which plays an important role in MI-BCI classiﬁcation process\n",
      "[32, 48, 49]. Thus, in the current study, we have considered four non-overlapping frequency\n",
      "bands including δ, θ, α, and β for feature extraction from original EEG data in our proposed\n",
      "CNN model. A ﬁlter bank of 1-4 Hz, 4-8 Hz, 8-13 Hz, and 13-30 Hz has been employed to\n",
      "extract EEG signal information in corresponding frequency bands.\n",
      "3.1 multi-scale convolution block (MSCB): In the proposed MSCB network, convolu-\n",
      "tion block λ has a relatively large convolution kernel size 1 × Ω which can capture the\n",
      "L L\n",
      "overall feature map of the EEG signal. Relatively medium convolution kernel size 1×Ω in\n",
      "M\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 8\n",
      "Table 1: Main network parameters of generalized multi-scale convolution block (MSCB) as\n",
      "shown in Fig. 3.\n",
      "Layer type Kernel size No of Kernel Stride Padding Feature map\n",
      "Convolution λ ΩC = 5 NλL = 14 SλL = 1 SAME L ×NλL\n",
      "L L K K s K\n",
      "Max Pool λ ΩP − SλL SAME (L /SλL)×NλL\n",
      "L L P s P K\n",
      "Convolution λ ΩC = 3 NλM = 14 SλM = 1 SAME L ×NλM\n",
      "M M K K s K\n",
      "Max Pool λ ΩP − SλM SAME (L /SλM)×NλM\n",
      "M M P s P K\n",
      "Convolution λ ΩC = 1 NλS = 14 SλS = 1 SAME L ×NλS\n",
      "S S K K s K\n",
      "Max Pool λ ΩP − SλS SAME (L /SλS)×NλS\n",
      "S S P s P K\n",
      "Max Pool λ ΩP - Sλ SAME (L /Sλ)×N\n",
      "P s P f\n",
      "Convolution λ ΩC Nλ = 24 Sλ = 1 SAME (L /Sλ)×Nλ\n",
      "K K s P K\n",
      "Concatenate - - - - (L /S )×56\n",
      "s P\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 9\n",
      "Table 2: Main network parameters of proposed multiscale CNN (MS-CNN) model as shown\n",
      "in Fig. 4.\n",
      "Layer type Kernel size No of Kernel Stride Padding Feature map\n",
      "MSCB - - - - (L /S )×56\n",
      "s P\n",
      "CL ΩCL 112 S = 1 SAME (L /S )×112\n",
      "CL s P\n",
      "MP ΩMP - S SAME L /(S ×S )×112\n",
      "PL s P PL\n",
      "1st FC - - - - 400\n",
      "Dropout layer - - - - -\n",
      "2nd FC - - - - 300\n",
      "Output layer - - - - 2\n",
      "convolutionblockλ canpreserverelativelycoarsegrainfeatureinformation. Finally, convolu-\n",
      "M\n",
      "tionblockλ withsmallkernelsize1×Ω caneﬃcientlycollectﬁne-grainlocalizeinformation.\n",
      "M S\n",
      "3.2 Multi-scale CNN (MS-CNN): The proposed multi-scale CNN architecture has been\n",
      "presented in Fig. 4. At ﬁrst, the inputted EEG signal has been divided into four diﬀer-\n",
      "ent frequency bands channels and passed through corresponding MSCB blocks (i.e., MSCB ,\n",
      "i\n",
      "i = δ,θ,α, and β) to obtain multi-scale features from the EEG signal as shown in Fig. 4.\n",
      "These MSCB blocks have been connected to convolution and then max-pooling layers. The\n",
      "kernel size of 1×ΩCL in convolution layer with stride S = 1 can preserve relatively coarse\n",
      "CL\n",
      "ﬁne-grain feature information. The subsequent max-pooling layer reduces the size of feature\n",
      "information utilizing ﬁlter size of ΩMP with stride S = 5. The extracted features from the\n",
      "PL\n",
      "max-pooling layer have been passed through the ﬁrst ﬂatten layer for feature fusion. During\n",
      "feature fusion, 2D feature vectors are transformed to 1D feature by row concatenation process\n",
      "for all four brunches as shown in Fig. 4. Finally, further concatenation operation transforms\n",
      "all the 1D features from the four branches into a 1D array which has been used as the input\n",
      "to the fully connected layer with number of hidden units N . The output of the network is\n",
      "h\n",
      "obtained by utilizing the Softmax layer that performs multi-class classiﬁcation of EEG signals.\n",
      "The proposed network utilizes ReLU as the primary activation function which accelerates the\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 10\n",
      " \n",
      " \n",
      "       δ-band (1-4 Hz) \n",
      "    \n",
      "      MSCB-δ             \n",
      "   \n",
      "         θ-band (4-8 Hz) \n",
      "                 MSCB-θ               reya  \n",
      "     L tup\n",
      "           α-ban d (8-13 Hz)   MSCB- α              tuO\n",
      "   \n",
      "       β-band (13-30 Hz) \n",
      "  \n",
      "   \n",
      "    Input Data    FreqCuheanncyn eBl a  nd    MultBi S lMoccaSkleC ( MCBo-SβnC vBol)u  t ion        noitul orvenyoaCL vnC o()      gnilooPr exyaaML    )LPM(    reyaL nettalF   )LF(    reyaL detcennoC ylluF )LCF(    reyaL detcennoC ylluF )LCF(   \n",
      "Figure 4: The schematic of proposed multi-scale CNN (MS-CNN) network architecture con-\n",
      "sisting of four diﬀerent MSCB as shown in Fig. 3 for eﬃcient multi-scale feature extraction for\n",
      "diﬀerent non-overlapping frequency bands.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 11\n",
      "optimization process of the MS-CNN network and increases the classiﬁcation accuracy for MI-\n",
      "BCI application [30]. Moreover, cross-entropy has been used as a loss function to optimize the\n",
      "model during training. The cross-entropy L for n classes can be deﬁned as:\n",
      "CE\n",
      "n\n",
      "(cid:88)\n",
      "L = − t log(p ) (2)\n",
      "CE i i\n",
      "i=1\n",
      "Where t is the truth label; p is the Softmax probability for ith class. In the proposed model,\n",
      "i i\n",
      "the trial matrix size of 1×N (where N is the numeber of data points of each EEG trials)\n",
      "Ls Ls\n",
      "from EEG signal data has been inputted in the MS-CNN; where L is the segment of EEG\n",
      "s\n",
      "signal in interest and N is the number of EEG channels. The time period of a MI trial ranges\n",
      "c\n",
      "from 3.5s to 7.5s as shown in Fig. 2-(b). Thus, with the sampling frequency of 250 Hz, we\n",
      "obtain a trial of L = 4s with N =1000 data points.\n",
      "s Ls\n",
      "4. EEG Feature Extraction:\n",
      "Due to inter-subject variability of the EEG signals, the accuracy of the classiﬁer often di-\n",
      "minish. Thus, it is critical to extract the user-speciﬁc features information from EEG data\n",
      "to improve classiﬁcation accuracy in MI based BCIs. Although there are many features such\n",
      "as statistical, time-domain, frequency-domain, wavelet, auto-regressive coeﬃcients can be ex-\n",
      "tracted from EEG signals [52], however, in the proposed framework, two highly discriminant\n",
      "user-speciﬁc features have been extracted and integrated in the MS-CNN model which improve\n",
      "the accuracy and performance of the model.\n",
      "4.1 Diﬀerential entropy: From the MI-EEG signal data segment, diﬀerential entropy\n",
      "(DE) feature has been extracted which demonstrated superior performance compared to com-\n",
      "monly used features [53]. The DE of a given EEG signal X satisfying the Gauss distribution\n",
      "N(µ,σ2) can be expressed as\n",
      "h(X) = −(cid:90) ∞ √ 1 e−(x2−σµ2)2 log(cid:18)√ 1 e−(x2−σµ2)2(cid:19)dx = 1 log2πeσ2 (3)\n",
      "2πσ2 2πσ2 2\n",
      "−∞\n",
      "Where σ is the standard deviation, ζ is the mean value. For a particular EEG signal segment,\n",
      "DE feature is equivalent to the logarithm energy spectrum in a distinct frequency band. Thus,\n",
      "a bandpass ﬁlter has been employed to extract four diﬀerent frequency bands δ (1–4 Hz), θ\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 12\n",
      "log(PSD) log(PSD)\n",
      "Event type : Left Event type : Right\n",
      "1 1 α-band (8-13 Hz)\n",
      "α-band (8-13 Hz)\n",
      "Center frequency \n",
      "Center frequency \n",
      "0 C3 0\n",
      "Bandwidth\n",
      "Bandwidth\n",
      "-1 Relative  power Cz -1 Relative  power\n",
      "Total power\n",
      "Total power\n",
      "-2\n",
      "-2 C\n",
      "4\n",
      "-3\n",
      "-3\n",
      "1 5 10 15 20 25 30 1 5 10 15 20 25 30\n",
      "(a) Frequency (Hz) (b) Frequency (Hz)\n",
      "Power ratio Power ratio Power ratio\n",
      "0.40 C3 EEvveenntt  ttyyppee  ::  LReigftht 0.40 Cz EEvveenntt  ttyyppee  ::  LReigftht 0.40 C4 EEvveenntt t tyyppee :  :L Refitght\n",
      "0.35 0.35 0.35\n",
      "0.30 PαL > PαR 0.30 PαL =PαR 0.30 PαL < PαR\n",
      "0.25 0.25 0.25\n",
      "0.20 0.20 0.20\n",
      "0.15 0.15 0.15\n",
      "δ θ α β δ θ α β δ θ α β\n",
      "(1-4 Hz) (4-8 Hz) (8-13 Hz) (13-30 Hz) (1-4 Hz) (4-8 Hz) (8-13 Hz) (13-30 Hz) (1-4 Hz) (4-8 Hz) (8-13 Hz) (13-30 Hz)\n",
      "(c) (d) (e)\n",
      "Figure 5: (a, b) NPS containing strong peak in α band (8-13 Hz, yellow and green region) and\n",
      "secondary θ (not marked) with overlapping nature of periodic and aperiodic spectral features\n",
      "for left and right event type, respectively ; (c, d, e) comparison of power ratio in left and right\n",
      "event type for four diﬀerent canonical frequency range from the electrodes C , C , and C .\n",
      "3 Z 4\n",
      "(4–8 Hz), α (8–13 Hz), and β (13-30 Hz) from each EEG channel. Subsequently, short-time\n",
      "Fourier transform has been employed with a non-overlapped hamming window of 4 s on trial\n",
      "EEG signal segment consist of 1000 data points to obtain the energy spectrum of each speciﬁed\n",
      "frequency band. Finally, the DE feature has been extracted by calculating the logarithm en-\n",
      "ergy spectrum for each of the aforementioned four frequency bands from single channel. After\n",
      "feature extraction, the shape of the DE feature matrix for each selected EEG segments has\n",
      "been concatenated with MS-CNN main feature matrix.\n",
      "4.2 Neural power spectra: Typically, EEG signal data has been analyzed using only\n",
      "canonically deﬁned frequency bands, ignoring the aperiodic component which may compro-\n",
      "mise physiological interpretations. However, the EEG neural data contains both periodic and\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 13\n",
      "aperiodic components [42]. Recently, the neural power spectra (NPS) model has been intro-\n",
      "duced which combines both aperiodic component and putative periodic oscillatory peaks [42].\n",
      "In this model, the neural PSD has been characterized by the power, speciﬁc center frequency,\n",
      "and bandwidth without requiring predeﬁning speciﬁc EEG frequency bands and controlling\n",
      "for the aperiodic component. Additionally, the characteristics of these aperiodic components\n",
      "allow one to measure and compare the 1/f-like components between inter-subject variability\n",
      "of the EEG signals. This model has been utilized to extract periodic and aperiodic features\n",
      "of EEG data in the present study. To measure the periodic activity, the power relative to\n",
      "the aperiodic component has been calculated with each peak can be described by Gaussian in\n",
      "terms of parameters a, c and w, where a is the height of the peak, over and above the aperiodic\n",
      "component; c is the center frequency of the peak; w is the width of the peak; F is the array of\n",
      "frequency values. Each Gaussian, n referred to as G(F) can be expressed as [42]:\n",
      "n\n",
      "G(F)n = ae−(F2−wc2)2 (4)\n",
      "Whereas, the aperiodic activity component without any characteristic frequency can be ex-\n",
      "pressed as the function L(F) as follows:\n",
      "L(F) = b−log(k +Fχ) (5)\n",
      "Where b is the broadband oﬀset; χ is the exponent of the aperiodic ﬁt; k is the ‘knee’. Finally,\n",
      "across a set of frequencies F, NPS can be expressed as NPS(F) = G(F) +L(F). For better\n",
      "n\n",
      "clarity, an example of NPS containing a strong peak in α band with overlapping nature of\n",
      "periodic and aperiodic spectral features for two classes have been shown in Fig. 5-(a, b). Con-\n",
      "sequently, the power ratio (spectral power in the bin normalized by power in all spectral bins\n",
      ") for four diﬀerent canonical frequency range from the electrodes C , C , and C reveals that\n",
      "3 Z 4\n",
      "the α range power decreases as shown in Fig. 5-(c, d, e) on the opposite (i.e. contralateral)\n",
      "hemisphere when MI on one side is performed for a particular class. The apparent diﬀerences\n",
      "between the diﬀerent electrode’s PSDs, in particular, relative PSDs of C (see Fig. 5-c) and C\n",
      "3 4\n",
      "(see Fig. 5-e) channels vary between the two MI classes. Clearly, NPS is a highly discriminant\n",
      "user-speciﬁc feature that improves the accuracy and performance of the model signiﬁcantly\n",
      "(see section 6.3 ). In the present study, NPS features containing periodic (c, w, and P ) and\n",
      "band\n",
      "aperiodic parameters (b,k, and χ) have been extracted for each of the four frequency bands for\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 14\n",
      "each channel and ﬁnally concatenated with MS-CNN main feature matrix as shown in Fig. 8.\n",
      "5. Data augmentation of EEG signal:\n",
      "In DL based MI-BCI system, the accuracy of the MI classiﬁer is greatly dependent on the\n",
      "volume of EEG training data. Without suﬃcient data, the accuracy may drop. Hence, to\n",
      "improve the accuracy and robustness of the CNN classiﬁer, data augmentation (DA) methods\n",
      "can be employed to generate new sample data from existing EEG training sample [54]. How-\n",
      "ever, improper DA might lead to a decrease in the performance of the classiﬁer. In the present\n",
      "study, four diﬀerent types of DA methods have been chosen and implemented speciﬁcally for\n",
      "EEG-based MI-BCI systems to increase the volume of EEG data during training and improve\n",
      "the performance of the classier (see section 6.4).\n",
      "5.1 Gaussian noise: In the ﬁrst DA method, noise has been added to the original train-\n",
      "ing data. The EEG signal has strong randomness and highly non-stationary characteristics.\n",
      "Thus, randomly added local noise may alter the important EEG feature. In order to preserve\n",
      "the important local feature of EEG data, Gaussian noise (GN) has been added to the original\n",
      "training data [53]. The probability density function P of a Gaussian random variable ξ can\n",
      "G\n",
      "be expressed as follows:\n",
      "PG(ξ) = √1 e−(ξ2−σζ2)2 (6)\n",
      "σ 2π\n",
      "Where σ is the standard deviation, ζ is the mean value. In the present work, ζ = 0 has been\n",
      "prescribed to ensure that the amplitude of the original EEG signal remain unchanged after the\n",
      "addition of noise. During DA, diﬀerent noise intensity i.e., σ=0.001, 0.005, 0.01, 0.05, 0.10,\n",
      "0.25, and 0.5 have been considered.\n",
      "5.2 Signal segmentation and recombination in time domain: Additionally, EEG data\n",
      "transformation including signal segmentation and recombination (S & R) has been utilized as\n",
      "a second DA method to further expand the dataset. In this procedure, each training EEG\n",
      "trial for the particular class has been subdivided into multiple segments and then new trials\n",
      "are generated by combining segments collected from diﬀerent and randomly selected trials\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 15\n",
      "  S im  S jn  S km \n",
      "S im  S jm  S km     \n",
      " \n",
      "DA trial- p  \n",
      "     \n",
      "   \n",
      "Trial   \n",
      "   m  \n",
      "      S in  S jn  S km \n",
      "      DA trial- q  \n",
      "S in  S jn  S kn       \n",
      "     \n",
      "T   rni a l  S im  S jn  S kn \n",
      "   \n",
      "  DA trial- N  \n",
      "   \n",
      "     \n",
      " \n",
      "Original trial from the same class  \n",
      "Time domain recombination   \n",
      "Segmentation   \n",
      "Figure 6: Procedure of EEG signal segmentation and recombination in time domain for data\n",
      "augmentation.\n",
      "from the same training class data [55]. If ∆ = {Si},i ∈ [1,n] is the set of total n number\n",
      "of EEG training data for given class, each training EEG trial Si for the particular class has\n",
      "been subdivided into K consecutive and non-overlapping segments Si and then generating a\n",
      "K\n",
      "new trials S˜j = [Sj ,Sj,...Sj] by combining segments from diﬀerent and randomly selected\n",
      "m n n\n",
      "training trials from the same class. The schematic of S & R - DA procedure has been shown\n",
      "in Fig. 6. Considering the original trials S and S from the same class have been segmented\n",
      "m n\n",
      "(cid:2) (cid:3) (cid:2) (cid:3)\n",
      "into ...,Si , Sj , Sk,... and ...,Si, Sj, Sk,... . These segments have been recombined in\n",
      "m m m n n n\n",
      "time domain to obtain N additional DA trials. In the present work, input EEG trials (i.e.\n",
      "left/right-hand MI) have been considered as same label with each trial has been segmented\n",
      "into 4 division with 250 data points (i.e., 1 sec long segment).\n",
      "5.3 Window slicing: In the window slicing (WS) DA method, EEG time series data have\n",
      "been extracted in slices and classiﬁcation has been performed at diﬀerent slice levels [56]. Dur-\n",
      "ing training, each slice of the corresponding class has been assigned to the same class where\n",
      "the size of the slice is one of the parameters for the DA. In the present work, a window of 90%\n",
      "of the training EEG data has been chosen randomly and interpolated back to the original size\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 16\n",
      " \n",
      "Wrap segment  \n",
      " Stretching     Shrink   \n",
      " \n",
      "           \n",
      "   \n",
      " \n",
      "(a)   (b)   (c)  \n",
      "Figure 7: Schematic of window warping data augmentation technique for EEG signal.\n",
      "to ﬁt with the classiﬁer [56, 57].\n",
      "5.4 Window Warping: In the last DA technique, window warping (WW) [56] DA has\n",
      "been utilized which expands or contracts random windows of the EEG training data by some\n",
      "speciﬁc value. Considering the length of the original EEG signal as a parameter, WW warps a\n",
      "randomly selected segment as shown in Fig. 7. Although, WW generates input time series of\n",
      "diﬀerent lengths, however, the issues can be overcome by performing DA on transformed EEG\n",
      "data having equal lengths [56]. The present study considers a random window of 10% of the\n",
      "original EEG data and wrapped it by speeding it up by 2 or slowing it down by 0.5.\n",
      "6. Results and discussion:\n",
      "In this section, the performance and accuracy of the proposed model have been discussed\n",
      "and compared with several existing methods. The BCI competition IV-2b EEG dataset in-\n",
      "cludes 9-subject and 2-class motor-imagery (right hand, left hand) with ﬁve sessions for each\n",
      "subject. The ﬁrst two sessions (identiﬁers: 01T and 02T ) have been used to train the classiﬁer\n",
      "for all models [35]. The third session (identiﬁers: 03T ) has been employed during validation.\n",
      "The last two sessions (identiﬁers: 04E and 05E ) have been strictly utilized for evaluating the\n",
      "corresponding trained classiﬁer [35, 36]. The EEG trial length of L = 4s with N =1000\n",
      "s Ls\n",
      "data points has been used. The proposed MS-CNN model has been ﬁne-tuned on the valida-\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 17\n",
      "Feature Extraction \n",
      "Data Augmentation \n",
      "Training EEG data \n",
      "Multi-scale CNN  (MSCNN)\n",
      "EEG data  test data \n",
      "C\n",
      "Trained Classifier \n",
      "MI classification \n",
      "Model training \n",
      "Figure 8: Flowchart representing the overall workﬂow of the proposed framework for EEG-\n",
      "based MI BCI system based on DA and feature integration.\n",
      "tion set and then applied to testing sets. The ﬁnal ﬁne-tuned network parameters Ω = 1,\n",
      "S\n",
      "ΩP = ΩP = ΩP = ΩP = 5, Ω = 3, SλL = SλM = SλS = Sλ = 5 and Ω = 5 have been pre-\n",
      "L M S M P P P K L\n",
      "scribed. During training, a batch size of 16 has been chosen to optimize the convergence speed\n",
      "and achieve higher classiﬁcation accuracy. In the proposed model, stochastic gradient descent\n",
      "(SGD) has been utilized as a training strategy with 500 epochs prescribing an exponential de-\n",
      "cay rate of 0.8 for optimizing the cross-entropy loss function. Due to the high conditionality of\n",
      "the optimization procedure in MI-BCI classiﬁcation, SGD reduces the computational burden\n",
      "by achieving faster convergence. The initial learning rate is set to 0.001 and the learning rate\n",
      "decays every 30 epochs with an exponential decay rate of 0.5. Lastly, L2 regularization with a\n",
      "regularization parameter value of 0.02 and dropout technique with a dropout probability value\n",
      "of 0.5 (in the ﬁrst FC layer) have been prescribed to prevent over-ﬁtting. Finally, the models\n",
      "were implemented using the Keras API with TensorFlow as the lower level backend library.\n",
      "Additionally, MNE v0.23 [58], PyEEG [59], NeuroDSP [60], and FOOOF [61] libraries have\n",
      "been utilized for data pre-processing, feature extraction, spectral-domain and NPS analysis.\n",
      "The ﬂowchart representing the overall workﬂow of the proposed framework has been shown\n",
      "in Fig. 8. For each subject, the experiment has been executed 10 times. The accuracy per-\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 18\n",
      "Avg. Accuracy (%)  Avg. Accuracy (%) \n",
      "100 100\n",
      "K-NN\n",
      "95 95\n",
      "90 LDA 90\n",
      "85 85\n",
      "80 SVM 80\n",
      "75 75\n",
      "CNN\n",
      "70 70\n",
      "65 65\n",
      "Proposed\n",
      "60 60\n",
      "MS-CNN\n",
      "55 55\n",
      "50 50\n",
      "  1 B011 B022  B033 B044  B05 5  B606  B707  B808  B909   \n",
      "(a)  (b) \n",
      "Figure 9: Comparison bar chart of (a) average accuracy with SE (in %) (b) average accuracy\n",
      "of each subject between K-NN, LDA, SVM, CNN, and proposed MS-CNN models.\n",
      "formance of the proposed framework is evaluated on the prepared testing set. The average\n",
      "√\n",
      "classiﬁcation accuracy and standard error (SE)= s/ n (s is the sample standard deviation; n\n",
      "is the sample size ) have been calculated from the test datasets.\n",
      "6.1 Performance comparison with diﬀerent algorithms: In this paper, the average\n",
      "classiﬁcation accuracy has been used to evaluate diﬀerent classiﬁcation models. The global av-\n",
      "eraged accuracy is deﬁned as the ratio of the number of correctly classiﬁed samples to the total\n",
      "number of samples. The performances of the proposed MS-CNN model has been compared\n",
      "with three popular traditional ML models in MI-BCI classiﬁcation: K-nearest neighbor(K-\n",
      "NN), linear discriminant analysis (LDA), and support-vector machine (SVM) as the baseline\n",
      "models. Additionally, the standard CNN model has also been considered as the baseline DL\n",
      "model. Note, the standard CNN structure consisting of 4 convolution and max-pooling lay-\n",
      "ers is deeper than the MS-CNN model. For fair comparison, all feature extraction and data\n",
      "augmentation methods have been applied in all aforementioned baseline models. Additionally,\n",
      "model hyper-parameters have prescribed the same as the proposed model. As shown in Table\n",
      "3, the proposed MS-CNN has obtained the best accuracy across all subjects among all baseline\n",
      "models with an average accuracy of 93.74% for the BCI competition IV-2b dataset. Compared\n",
      "to K-NN, LDA, and SVM, it has achieved d 26.76%, 24.75%, and 26.96% improvement in av-\n",
      "erage classiﬁcation accuracy, respectively. The proposed model has achieved 16.92% accuracy\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 19\n",
      "Table3: AverageaccuracyvaluesofeachsubjectfromK-NN,LDA,SVM,CNN,andproposed\n",
      "MS-CNN models where bold indicates the best result from the corresponding model\n",
      "Average Accuracy\n",
      "Subject\n",
      "K-NN LDA SVM CNN MS-CNN\n",
      "B01 68.32 68.77 69.45 74.52 93.45\n",
      "B02 54.39 56.46 58.92 61.29 88.71\n",
      "B03 60.77 61.29 63.89 73.67 89.14\n",
      "B04 80.22 84.49 90.22 91.45 95.37\n",
      "B05 72.17 74.32 76.23 81.43 95.11\n",
      "B06 63.89 70.35 71.47 76.89 93.82\n",
      "B07 66.32 65.60 69.68 75.89 94.70\n",
      "B08 71.17 72.12 73.41 78.83 96.81\n",
      "B09 64.97 67.55 69.77 76.82 96.73\n",
      "Avg. Accuracy with SE 66.98 ±1.67 68.99 ±1.49 71.45 ±2.01 76.76 ±1.84 93.74±1.09\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 20\n",
      "Left-MI\n",
      "100 ROC curve\n",
      "90 1\n",
      " % 80\n",
      " yca 6700 SVM 0.9\n",
      "ruccA 345000 CMNSN-CNN 0.8\n",
      "20 0.7\n",
      "10\n",
      "0 P 1 R2 F3-1 etaR 0.6\n",
      "19000 Right-MI  evitisoP eurT 000...345 MMS-CSN-NCNN (AUC=0.952)\n",
      "80 CCNNNN  (AUC=0.785)\n",
      " % 70 0.2\n",
      " yca 5600 SCVNMN 0.1 SVSNVM  (AUC=0.733)\n",
      "ruccA 3400 MS-CNN 0\n",
      "20\n",
      "0 0.2 0.4 0.6 0.8 1\n",
      "10\n",
      "0 False Positive Rate\n",
      "P1 R2 F-31\n",
      "(a) (b)\n",
      "Figure 10: (a) Comparison bar chart of P, R, F-1 (in %) for the two diﬀerent MI (left and\n",
      "right hand); (b) ROC curves and corresponding AUC values obtained from SVM, CNN, and\n",
      "MS-CNN models.\n",
      "improvement over the standard CNN model as shown in Fig. 9 indicating the superior perfor-\n",
      "mance of MS-CNN. Additionally, the MS-CNN model has the lowest SE value which indicates\n",
      "that the proposed model has the capability of the subject-independent representation of EEG\n",
      "data and better generalization of the classiﬁer compared to other baseline methods. Further-\n",
      "more, the performance of MS-CNN model on the recognition of two diﬀerent MI classes (left\n",
      "and right hand ) have been measured by precision (P), recall (R), and F1-score and compared\n",
      "with SVM and standard CNN model as shown in Fig. 10- (a). For binary classiﬁcation, sample\n",
      "data can be classiﬁed into four diﬀerent categories: true positive (TP), false positive (FP), true\n",
      "negative (TN), and false negative (FN), based on the true class and the model-predicted class.\n",
      "The evaluation matrices P, R, F1 can be deﬁned as\n",
      "TP TP\n",
      "P = ; R = (7)\n",
      "(TP +FP) (TP +FN)\n",
      "2PR\n",
      "F1 = . (8)\n",
      "(P +R)\n",
      "The larger values of P, R, F1 indicate better performance of the model. The proposed MS-\n",
      "CNN model has achieved best P, R, F1 values of 97.25%, 93.99%, 95.59% and 94.15%, 91.22%,\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 21\n",
      "92.66% for left and right MI, respectively. Finally, ROC (receiver operating characteristic)\n",
      "curve has been plotted from the true positive rate (TPR) or R (in the ordinate) and false\n",
      "positive rate (FPR) data (in the abscissa) from SVM, standard CNN, and MS-CNN result as\n",
      "shown in Fig. 10- (b). The area under the ROC curve is expressed in AUC and ranges from\n",
      "0.5 to 1. The closer the AUC is to 1.0, the higher the performance of the model. As shown in\n",
      "Fig. 10- (b), SVM, standard CNN, and MS-CNN have achieved AUC values of 0.733, 0.785,\n",
      "and 0.952, respectively indicating the best performance of MS-CNN compared to other clas-\n",
      "siﬁcation models. The total number of trainable network parameters of MS-CNN is 297,056\n",
      "compared to 334,236 of the standard CNN. Both models take a similar average time-frame\n",
      "(within 2 min) to train, whereas standard CNN takes a slightly higher training time due to a\n",
      "higher number of trainable parameters. The comparison demonstrates that the MS-CNN can\n",
      "have signiﬁcantly better accuracy and learning capability for diﬀerent subject classes with less\n",
      "training time. It is noteworthy to mention, both DL-based standard CNN and MS-CNN mod-\n",
      "els demonstrate superior performance in MI classiﬁcation accuracy than traditional baseline\n",
      "ML models for all subjects. The comparison illustrates the advantages of the DL model for\n",
      "its strong feature extraction capability and capturing abstract-advanced information among\n",
      "diﬀerent subjects compared to traditional ML methods in EEG-based MI-BCI systems.\n",
      "6.2 Inﬂuence of convolution kernel size : In this section, diﬀerent combinations of the\n",
      "convolution kernel size (i.e, Ω , Ω , and Ω ) in MSCB have been studied to explore the in-\n",
      "S M L\n",
      "ﬂuence of kernel sizes on the performance of the model. From the comparison as shown in Fig.\n",
      "11, it can be shown that with increasing kernel size, in particular, for combinations (Ω = 3,\n",
      "S\n",
      "Ω = 7, Ω = 9) and (Ω = 3, Ω = 9, Ω = 11) classiﬁcation accuracy drops to 89.78% and\n",
      "M L S M L\n",
      "87.39%, respectively. However, the combination of relatively small kernel size, classiﬁcation\n",
      "accuracy, as well as speed, improves. Comparing all the results, it can be found that the best\n",
      "classiﬁcation result corresponds to (Ω = 1, Ω = 5, Ω = 7) with an accuracy of 93.99%.\n",
      "S M L\n",
      "However, in this study, combinations of Ω = 1, Ω = 3, and Ω = 5 has been selected which\n",
      "S M L\n",
      "is computationally more eﬃcient for real-time MI BCI system compromising only 0.25% accu-\n",
      "racy compared to result corresponds to (Ω = 1, Ω = 5, Ω = 7). Additionally, the selected\n",
      "S M L\n",
      "combination of kernel scales has achieved the smallest SE value of 1.09%, which is 0.20% lower\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 22\n",
      "Avg. Accuracy (%) \n",
      "100\n",
      "1Ω =1, Ω =3, Ω =5 \n",
      "  S M L\n",
      "98.5\n",
      "2 Ω =1, Ω =5, Ω =7 \n",
      "S M L\n",
      "97\n",
      "3  Ω =1, Ω =7, Ω =9 \n",
      "S M L\n",
      "95.5\n",
      "4  Ω  S=3, ΩM=5, ΩL=7 \n",
      "94\n",
      "5 Ω   =3, Ω =7, Ω =9 \n",
      "S M L\n",
      "92.5\n",
      "6 Ω   S=3, ΩM=9, ΩL=11 \n",
      "91\n",
      "   \n",
      "89.5\n",
      "  \n",
      "88\n",
      " \n",
      "86.5\n",
      "85\n",
      "  1\n",
      "Kernels combination   ` \n",
      " \n",
      "Figure11: ComparisonbarchartofaverageaccuracywithSE(in%)fordiﬀerentcombinations\n",
      "of convolutional kernel sizes in multi-scale convolution block (MSCB).\n",
      "Table 4: Inﬂuence of diﬀerent intrinsic feature extraction techniques on the average classiﬁ-\n",
      "cation accuracy of the proposed MS-CNN model.\n",
      "Average Accuracy with SE (%)\n",
      "No FE DE NPS All\n",
      "77.67 ±1.89 83.19 ±1.67 86.88 ±1.42 88.65±1.24\n",
      "than the best result. Hence, the chosen combination of kernel sizes in MSCB optimizes the\n",
      "performance of the MS-CNN model in-terms of both classiﬁcation accuracy and speed.\n",
      "6.3 Inﬂuence of feature extraction : In this study, the inﬂuence of diﬀerent feature ex-\n",
      "traction (FE) techniques on classiﬁcation accuracy has been explored as shown in Table 4.\n",
      "At ﬁrst, diﬀerent feature extraction methods that include DE and NPS have been considered\n",
      "individually and the corresponding accuracy of the classiﬁer has been determined. Finally,\n",
      "both the future extraction methods have been employed to obtain the ﬁnal accuracy of the\n",
      "model. Note, DA methods have not been considered during this study. From the comparison\n",
      "in Fig. 12-(a), it is clear that feature integration signiﬁcantly improves the accuracy of the\n",
      "model when accuracy increases 10.98% compared to the situation when the proposed model\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 23\n",
      "Table 5: Inﬂuence of data augmentation methods on the average classiﬁcation accuracy of\n",
      "the proposed MS-CNN model.\n",
      "Average Accuracy with SE (%)\n",
      "No DA GN S & R WS WW All\n",
      "77.67 ±1.89 78.96 ±1.96 81.56 ±1.65 78.81±1.84 77.92±1.55 83.68±1.34\n",
      "Avg. Accuracy (%)  Avg. Accuracy (%) \n",
      "100 100\n",
      "95 95 No DA\n",
      "NO FE\n",
      "GN\n",
      "90 90\n",
      "DE SR\n",
      "85 NPS 85 WS\n",
      "WW\n",
      "All\n",
      "80 80\n",
      "All\n",
      "75 75\n",
      "70 70\n",
      "  1                          1     \n",
      "(b) \n",
      "(a) \n",
      "Figure 12: Comparison bar chart of average accuracy with SE (in %) for the inﬂuence of\n",
      "diﬀerent (a) feature extraction techniques; (b) data augmentation methods in the proposed\n",
      "MI-BCI classiﬁcation framework.\n",
      "does not utilize any FE techniques. It is noteworthy to mention, the inﬂuence of NPS on the\n",
      "performance of the model is signiﬁcant with 9.21% accuracy gain. From the analysis, it can be\n",
      "inferred that both DE and NPS FEs play an important role for improving overall performance\n",
      "of the MS-CNN model.\n",
      "6.4 Inﬂuence of data augumentation methods: In the section, the inﬂuence of diﬀerent\n",
      "data augmentation (DA) methods including Gaussian noise (GN), segmentation and recom-\n",
      "bination (S & R), window sliding (WS), and window wrapping (WW) have been evaluated\n",
      "on the performance of the classiﬁer. Note, FE techniques have not been employed during\n",
      "the comparison. As shown in Table 5, the proposed model has reached the accuracy value of\n",
      "77.67% without any DA. However, diﬀerent DA methods improve the accuracy individually, in\n",
      "particular, there is a 3.89% accuracy gain by employing S & R. The combined eﬀect of all DE\n",
      "methods demonstrated an overall 6.01% accuracy improvement indicating the importance of\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 24\n",
      "Table 6: Comparison of the κ values for diﬀerent subjects with existing state-of-the-art ML\n",
      "models with bold indicates the best result from the corresponding model.\n",
      "Subject\n",
      "Method\n",
      "B01 B02 B03 B04 B05 B06 B07 B08 B09 Avg\n",
      "CSP+EMD-SVM[66] 0.44 0.35 0.32 0.60 0.33 0.32 0.51 0.61 0.37 0.42\n",
      "CSP-PSO based LSTSVM [63] 0.31 0.17 0.19 0.88 0.47 0.58 0.63 0.71 0.54 0.50\n",
      "HT-SVM, LDA [65] 0.61 0.31 0.32 0.99 0.78 0.72 0.63 0.78 0.74 0.65\n",
      "FBCSP-SVM[64] 0.48 0.29 0.25 0.97 0.98 0.70 0.67 0.84 0.79 0.66\n",
      "WPD+SE-Isomap K-NN[16] 0.69 0.33 0.26 0.92 0.78 0.96 0.64 0.73 0.94 0.70\n",
      "Proposed MS-CNN 0.92 0.867 0.89 0.95 0.94 0.91 0.94 0.92 0.95 0.92\n",
      "proposed DA methods for achieving better performance and robustness of the current frame-\n",
      "work.\n",
      "6.5 Comparison with diﬀerent state-of-the-art ML models : In order to evaluate and\n",
      "compare with the performance of diﬀerent ML classiﬁcation models, average Cohen’s kappa-\n",
      "coeﬃcient (κ) has been utilized to measure the accuracy of the corresponding classiﬁer. In\n",
      "Table 6, κ values obtained from the MS-CNN model have been compared with some of state-\n",
      "of-the-art machine learning models for BCI Competition IV 2b datasets. These ML models\n",
      "have utilized diﬀerent feature extraction methodologies including CSP [63], ﬁlter bank CSP\n",
      "(FBCSP) [64], Hilbert transform (HT) [65], wavelet packet decomposition (WPD) [16], and\n",
      "empirical mode decomposition (EMD) algorithm considering diﬀerent classiﬁcation methods\n",
      "such as SVM [64, 66], least squares twin SVM (LSTSVM) [63], LDA [65], and K-NN [16].\n",
      "From the overall comparison, it can be seen that the proposed MS-CNN model outshines\n",
      "other ML models signiﬁcantly in terms of κ values for all nine subjects, as shown in Fig.\n",
      "13. Comparing average κ, MS-CNN has achieved the highest κ value of 0.92 which is 22.2%\n",
      "and 26.01% improvement over the state-of-the-art ML methods in [16] and [64], respectively.\n",
      "∗Ref. [25] do not state accuracy values for each subject.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 25\n",
      "  B01\n",
      "Proposed MS-CNN\n",
      "B02\n",
      "WPD SE K-NN \n",
      "B03\n",
      "FBCSP-SVM  B04\n",
      "B05\n",
      "HT-SVM, LDA \n",
      "B06\n",
      "CSP-PSO LSTSVM \n",
      "B07\n",
      "CSP+EMD-SVM  B08\n",
      "B09\n",
      "0 2 4 6 8\n",
      " \n",
      "κ  \n",
      "Figure 13: Comparison of κ values for each subject between the proposed model (MS-CNN)\n",
      "and other state-of-the-art ML models considering diﬀrent feature extraction methods and clas-\n",
      "siﬁcation algorithms.\n",
      "Table 7: Comparison of accuracy (in %) of diﬀerent subjects with existing state-of-the-art DL\n",
      "models where bold indicates the best result from the corresponding model.\n",
      "Subjects\n",
      "DL Model\n",
      "B01 B02 B03 B04 B05 B06 B07 B08 B09 Avg.\n",
      "SCCNN∗ [25] - - - - - - - - - 64.00\n",
      "DTCNN[29] 72.6 60.3 66.9 91.2 80.6 70.6 73.2 77.7 71.2 73.77\n",
      "CNN+SAE[14] 76.0 65.8 75.3 95.3 83.0 79.5 74.5 75.3 73.3 77.6\n",
      "1DMSCNN[30] 80.56 65.44 65.97 99.32 89.19 86.1 81.25 88.82 86.81 82.61\n",
      "FDBN[27] 81.0 65.0 66.0 98.0 93.0 88.0 82.0 94.0 91.0 84.0\n",
      "HS-CNN[32] 80.5 70.6 85.6 94.6 98.3 86.6 89.6 95.6 87.4 87.6\n",
      "Proposed MS-CNN 93.4 88.7 89.1 95.3 95.1 93.8 94.7 96.8 96.7 93.74\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 26\n",
      "Accuracy (%) \n",
      "100\n",
      "95\n",
      "90\n",
      "DTCNN\n",
      "85\n",
      "CNN+SAE\n",
      "80\n",
      "75 1DMSCNN\n",
      "70 FDBN\n",
      "65\n",
      "HS-CNN\n",
      "60\n",
      "Proposed MS-CNN\n",
      "55\n",
      "50\n",
      "B011  B202  B303  B404  5B05  6B06  7B07  8B08  9B09  10Avg \n",
      " \n",
      "Figure14: Comparisonbarchartofthesubjectandaverageaccuracy(in%)betweenproposed\n",
      "model (MS-CNN) and other state-of-the-art DL models for all diﬀerent subjects.\n",
      "6.6 Comparison with diﬀerent state-of-the-art DL models : In this section, the accu-\n",
      "racy of several state-of-the-art advanced DL models such as separated channel convolutional\n",
      "neural network (SCCNN)[25], deep transfer CNN (DTCNN) [29], CNN and stacked autoen-\n",
      "coders (CNN+SAE) [14], 1-D multi-scale CNN (1DMSCNN) [30], frequential deep belief net-\n",
      "work (FDBN) [27], and hybrid-scale CNN (HS-CNN) [32] have been compared with the pro-\n",
      "posed model as detailed in Table 7. It can be seen that the proposed MS-CNN model attains\n",
      "the highest average classiﬁcation accuracy of 93.74% among other DL models. It is noteworthy\n",
      "to mention that the proposed model improves the average classiﬁcation accuracy of 11.13%,\n",
      "9.74%, and 6.14% over the recent and more advanced DL models 1DMSCNN, FDBN and HS-\n",
      "CNN, respectively, as shown in Fig. 14. More speciﬁcally, MS-CNN demonstrated signiﬁcant\n",
      "classiﬁcation accuracy improvement in subject B01 (up to 12.9% increase), B02 (up to 18.1%\n",
      "increase), B06 (up to 7.2% increase), B09 (up to 9.3% increase) which indicates the eﬃciency\n",
      "and robustness of the proposed model. From the aforementioned comparison of classiﬁcation\n",
      "accuracy and κ value, it can be inferred that the proposed MS-CNN model demonstrates better\n",
      "accuracythanthestate-of-the-artdiﬀerentMLandadvancedDLalgorithmsforallthesubjects\n",
      "with the lowest SE. The result indicates the capability of subject-independent representation\n",
      "of EEG data and better generalization of the proposed classiﬁer.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 27\n",
      "7. Discussion :\n",
      "The current study demonstrates that MS-CNN with DA methods and feature integration tech-\n",
      "niques signiﬁcantly improves the accuracy of two class MI-based BCI applications emphasizing\n",
      "the prospect of the current framework in adopting the distinguishable feature of MI-EEG sig-\n",
      "nals. Additionally, the current model reduces the computational burden in MSCB and thus,\n",
      "increase the speed of the classiﬁer. However, the present work focuses on MI-BCI classiﬁcation\n",
      "tasks for the subject-dependent scenario, where the model has been trained and evaluated\n",
      "on the same subject. The future direction of the current work can be geared toward realiz-\n",
      "ing subject-independent classiﬁcation [67] where the evaluation phase is independent of the\n",
      "particular subject training class. Additionally, where high-performance person-independent\n",
      "classiﬁcation is compulsory for the wide application of BCI Systems in the real-world, one\n",
      "possible solution to achieving the goal is to build a personalized model with transfer learn-\n",
      "ing. An eﬃcient transfer model can adopt a transductive parameter to construct an individual\n",
      "classiﬁer which can be further extended to an adaptive-based transfer learning classiﬁer [68].\n",
      "Another direction could be the implementation of unsupervised or semi-supervised learning\n",
      "[69] to circumvent expensive and time-consuming manual labeling in unsupervised learning\n",
      "to perform classiﬁcation tasks in abundant class labels for a wide range of MI-BCI scenarios.\n",
      "Moreover, in future work, classiﬁcation accuracy can be further improved by integrating long\n",
      "short-term memory (LSTM) recurrent neural network (RNN) architecture [70] or self-attention\n",
      "based transformer [71] for extracting semantic temporal-spatial feature of EEG signal and ex-\n",
      "pend the proposed framework for classifying multi-class MI for diﬀerent BCI applications.\n",
      "Here, some important future research directions, in particular, geared toward the applications\n",
      "of BCI in the healthcare community have been acknowledged. Firstly, the current framework\n",
      "can be utilized in medical and health care, where the deep learning-based BCI systems pre-\n",
      "dominantly work on the detection and diagnosis of mental diseases such as sleeping disorders,\n",
      "Alzheimer’s Disease, epileptic seizure, and other disorders. The MS-CNN model can be widely\n",
      "adopted for its feature engineering and real-time classiﬁcation for spontaneous EEG stream-\n",
      "basedneurodegenerativediseasessuchasParkinson’sdisease[72]. Moreover, thecurrentmodel\n",
      "can be suitable for classifying AD based on spontaneous EEG [73] and diagnosis of an epileptic\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 28\n",
      "seizure. In such scenarios, a hybrid model containing recurrent neural network (RNN) archi-\n",
      "tecture attached to the MS-CNN model considering tempo-spatial feature extraction can be\n",
      "utilized in seizure diagnosis [74, 75]. Additionally, diﬀerent mental diseases such as depression\n",
      "[76], Interictal Epileptic Discharge (IED) [77], schizophrenia [78], Creutzfeldt-Jakob disease\n",
      "(CJD) [79], and Mild Cognitive Impairment (MCI) [80] can be detected employing the current\n",
      "BCI deep learning model. Furthermore, the current framework can be extended as a more\n",
      "reliable and robust MI-based real-time brain signal based communications applications such\n",
      "as robotic control [5, 6, 7], P300 speller [81], rehabilitation of neuromotor disorders [4], text\n",
      "entry speech communication [8, 9], cognitive load measurement [82], gaming [2, 3] etc. The\n",
      "current model can be extended to various material modeling [83, 84, 85, 86, 87, 88, 89, 90]\n",
      "8. Conclusion :\n",
      "Summarizing, in this study, a multi-scale convolutional neural network has been designed for\n",
      "EEG-based MI classiﬁcation. The multi-scale convolution block consisting of diﬀerent convo-\n",
      "lutional kernel sizes in the proposed model can extract semantic features in multiple scales for\n",
      "diﬀerent frequency bands δ, θ, α, and β from original EEG data for the classiﬁcation purpose.\n",
      "Several intrinsic and user-speciﬁc features have been extracted from the original EEG data and\n",
      "integrated into the proposed algorithm to improve the accuracy and performance of the model.\n",
      "Furthermore, various data augmentation methods have been utilized to further improve the\n",
      "accuracy and robustness of the proposed classiﬁer by increasing training EEG data. In order\n",
      "to validate the eﬀectiveness of the framework, the proposed model has been applied to the\n",
      "BCI competition IV-2b dataset. Compared with other existing state-of-the-art algorithms, the\n",
      "classiﬁcation accuracy of the current algorithm has been signiﬁcantly improved. The results\n",
      "show that the proposed algorithm can attain high classiﬁcation accuracy with the character-\n",
      "istic of similar performance among the diﬀerent subjects. With average accuracy of 93.74%,\n",
      "the current framework demonstrates excellent classiﬁcation performance and generalization. It\n",
      "improves the average classiﬁcation accuracy of 11.13%, 9.74%, and 6.14% over the recent and\n",
      "more advanced DL models 1DMSCNN, FDBN and HS-CNN (with up to 18.1% increase of\n",
      "accuracy in the subject-speciﬁc case), respectively. The proposed model can extract more ef-\n",
      "fective features from EEG signals and can be used to design the eﬃcient and accurate real-time\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 29\n",
      "MI-based BCI framework.\n",
      "References\n",
      "[1] Liu Z, Shore J, Wang M, Yuan F, Buss A, Zhao X (2021). A systematic review on hybrid\n",
      "EEG/fNIRS in brain-computer interface. Biomedical Signal Processing and Control, 68:\n",
      "102595.\n",
      "[2] Pan H, Mi W, Lei X, Deng J (2020). A closed-loop brain–machine interface framework\n",
      "design for motor rehabilitation. Biomedical Signal Processing and Control, 58: 101877.\n",
      "[3] Sharma R, Kim M, Gupta A (2022). Motor imagery classiﬁcation in brain-machine in-\n",
      "terface with machine learning algorithms: Classical approach to multi-layer perceptron\n",
      "model. Biomedical Signal Processing and Control, 71: 103101.\n",
      "[4] Zhang Z, Sun J, Chen T (2022). A new dynamically convergent diﬀerential neural network\n",
      "for brain signal recognition. Biomedical Signal Processing and Control, 71: 103130.\n",
      "[5] Wang H, Dong X, Chen Z, Shi BE (2015) Hybrid gaze/EEG brain computer interface for\n",
      "robot arm control on a pick and place task. 37th Annual International Conference of the\n",
      "IEEE Engineering in Medicine and Biology Society (EMBC) 1476–1479.\n",
      "[6] Liao LD, Chen CY, Wang IJ, Chen S.F., Li SY, Chen BW, Chang JY, Lin CT (2012)\n",
      "Gaming control using a wearable and wireless EEG-based brain-computer interface device\n",
      "with novel dry foam-based sensors. Journal of Neuroengineering and Rehabilitation 9:5.\n",
      "[7] LaFleur K, Cassady K, Doud A, Shades K, Rogin E, He B (2013) Quadcopter control in\n",
      "three-dimensional space using a noninvasive motor imagery-based brain–computer inter-\n",
      "face. Journal of Neural Engineering 10 (4):046003.\n",
      "[8] Hossain MS, Amin SU, Alsulaiman M, Muhammad G (2019) Applying deep learning\n",
      "for epilepsy seizure detection and brain mapping visualization. ACM Trans Multimedia\n",
      "Comput Commun 1–17.\n",
      "[9] Makin JG, Moses DA, Chang EF (2020) Machine translation of cortical activity to text\n",
      "with an encoder–decoder framework. Nature Neuroscience 23(4): 575-582.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 30\n",
      "[10] Xing J, Qiu S, Ma X, Wu C, Li J, Wang S, He H.(2020) A CNN-based comparing net-\n",
      "work for the detection of steady-state visual evoked potential responses. Neurocomputing\n",
      "403:452-61.\n",
      "[11] Pfurtscheller G, Brunner C, Schlogl A, Lopes da Silva FH (2006) Mu rhythm\n",
      "(de)synchronization and EEG single-trial classiﬁcation of diﬀerent motor imagery tasks.\n",
      "Neuroimage 31:153-9.\n",
      "[12] Yu T, Xiao J, Wang F, Zhang R, Gu Z, Cichocki A, Li Y (2015). Enhanced motor imagery\n",
      "training using a hybrid BCI with feedback. IEEE Transactions on Biomedical Engineering\n",
      "62 (7):1706–1717.\n",
      "[13] Gandhi T, Panigrahi BK, Anand S (2011) A comparative study of wavelet families for\n",
      "EEG signal classiﬁcation. Neurocomputing 74:3051–7.\n",
      "[14] Tabar YR, Halici U (2017) A novel deep learning approach for classiﬁcation of EEG motor\n",
      "imagery signals. J Neural Eng 14:016003.\n",
      "[15] Luo J, Feng Z, Zhang J, Lu N (2016) Dynamic frequency feature selection based approach\n",
      "for classiﬁcation of motor imageries. Comput Biol Med 75:45–53.\n",
      "[16] Li M, Zhu W, Liu H, Yang J (2017) Adaptive Feature Extraction of Motor Imagery EEG\n",
      "with Optimal Wavelet Packets and SE-Isomap. Applied Sciences 7:390.\n",
      "[17] Saa JFD, C¸etin M (2012) A latent discriminative model-based approach for classiﬁcation\n",
      "of imaginary motor tasks from EEG data. Journal of neural engineering 9:026020.\n",
      "[18] Ang KK, Chin ZY, Zhang H, Guan C (2008) Filter Bank Common Spatial Pattern\n",
      "(FBCSP)inBrain-ComputerInterface.2008IEEEInternationalJointConferenceonNeu-\n",
      "ral Networks 2390–7.\n",
      "[19] Huang C, Tian G, Lan Y, Hao Y, Cheng Y, Peng Y, Che W (2019) A new Pulse Coupled\n",
      "Neural Network (PCNN) for Brain Medical Image Fusion empowered by Shuﬄed Frog\n",
      "Leaping. Frontiers in Neuroscience 13:210.\n",
      "[20] Sturm I, Lapuschkin S, Samek W, Mu¨ller KR (2016) Interpretable deep neural networks\n",
      "for single-trial EEG classiﬁcation. Journal of neuroscience methods 274:141–145.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 31\n",
      "[21] Schirrmeister RT, Springenberg JT, Fiederer LDJ, Glasstetter M, Eggensperger K,\n",
      "Tangermann M, Hutter F, Burgard W, Ball T (2017) Deep learning with convolutional\n",
      "neural networks for EEG decoding and visualization. Hum Brain Mapp 38:5391–5420.\n",
      "[22] Chu Y, Zhao X, Zou Y, Xu W, Han J, Zhao Y (2018) A decoding scheme for incomplete\n",
      "motor imagery EEG with deep belief network. Frontiers in Neuroscience 12:680.\n",
      "[23] Dose H, Møller JS, Iversen HK, Puthusserypady S (2018) An end-to-end deep learning\n",
      "approach to MI-EEG signal classiﬁcation for BCIs. Expert Systems with Applications\n",
      "114:532–542.\n",
      "[24] Sun Y, Lo FPW, Lo B (2019) EEG-based user identiﬁcation system using\n",
      "1D–convolutional long short-term memory neural networks. Expert Systems with Ap-\n",
      "plications 125:259–267.\n",
      "[25] Zhu X, Li P, Li C, Yao D, Zhang R, Xu P (2019) Separated channel convolutional neural\n",
      "network to realize the training free motor imagery BCI systems. Biomed Signal Process\n",
      "Control 49:396–403.\n",
      "[26] Xu B, Zhang L, Song A, Wu C, Li W, Zhang D, Xu G, Li H, Zeng H (2018) Wavelet\n",
      "trans- form time-frequency image and convolutional network-based motor imagery EEG\n",
      "classiﬁcation. IEEE Access 7:6084–6093.\n",
      "[27] Lu N, Li T, Ren X, Miao H (2017) A Deep Learning Scheme for Motor Imagery Classiﬁ-\n",
      "cation based on Restricted Boltzmann Machines. IEEE Transactions on Neural Systems\n",
      "and Rehabilitation Engineering 25:566–76.\n",
      "[28] Lawhern VJ, Solon AJ, Waytowich NR, Gordon SM, Hung CP, Lance BJ (2016) EEGNet:\n",
      "A Compact Convolutional Network for EEG-based Brain-Computer Interfaces. Journal of\n",
      "Neural Engineering 15:5.\n",
      "[29] Xu G, Shen X, Chen S, Zong Y, Zhang C, Yue H, Liu M, Chen F, Che W (2019) A\n",
      "deep transfer convolutional neural network framework for EEG signal classiﬁcation. IEEE\n",
      "Access 7:112767-112776.\n",
      "[30] Tang X, Li W, Li X, Ma W, Dang X (2020) Motor imagery EEG recognition based\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 32\n",
      "on conditional optimization empirical mode decomposition and multi-scale convolutional\n",
      "neural network. Expert Sys with Appl 149:113285.\n",
      "¨\n",
      "[31] Nour M, Oztu¨rk S¸, Polat K (2021) A novel classiﬁcation framework using multiple band-\n",
      "width method with optimized CNN for brain–computer interfaces with EEG-fNIRS sig-\n",
      "nals. Neural Comput Applic https://doi.org/10.1007/s00521-021-06202-4.\n",
      "[32] Dai G, Zhou J, Huang J, Wang N (2020) HS-CNN: a CNN with hybrid convolution scale\n",
      "for EEG motor imagery classiﬁcation. Journal of neural engineering 17(1):016025.\n",
      "˜\n",
      "[33] Leeb R, Brunner C, MAijller-PutzR G [Online]. Available:\n",
      "http://www.bbci.de/competition/iv/, Accessed on: March. 6, 2021.\n",
      "[34] Klem GH, Lu¨ders HO, Jasper HH and Elger C (1999) The ten-twenty electrode system\n",
      "of the International Federation. The International Federation of Clinical Neurophysiology\n",
      "Electroencephalogr Clin Neurophysiol Suppl 52:3–6.\n",
      "[35] Tangermann M, Mu¨ller KR, Aertsen A, Birbaumer N, Braun C, Brunner C, Leeb R,\n",
      "Mehring C, Miller KJ, Mueller-Putz G (2012) Review of the BCI competition IV. Front\n",
      "Neurosci 6:55.\n",
      "[36] Leeb R, Brunner C, Mu¨ller-Putz G, Schlo¨gl A, Pfurtscheller G (2008) BCI Competition\n",
      "2008–Graz data set B. Graz Univ Technol Austria 1–6.\n",
      "[37] Dagdevir E, Tokmakci M (2021) Determination of Eﬀective Signal Processing Stages for\n",
      "Brain Computer Interface on BCI Competition IV Data Set 2b: A Review Study. IETE\n",
      "Journal of Research 1-12.\n",
      "[38] LeCun Y, Bengio Y and Hinton G (2015) Deep learning. Nature 521:436–44.\n",
      "[39] Roy A.M. and Bhaduri J, (2021) A Deep Learning Enabled Multi-Class Plant Disease\n",
      "Detection Model Based on Computer Vision. AI 2(3): 413-428.\n",
      "[40] Roy A.M., Bose R. and Bhaduri, J. (2021) A fast accurate ﬁne-grain object detection\n",
      "model based on YOLOv4 deep neural network. arXiv preprint arXiv:2111.00298.\n",
      "[41] Zhang X, Yao L, Sheng Z, Kanhere SS, Gu T, Zhang D (2018) Converting your thoughts\n",
      "to texts: Enabling brain typing via deep feature learning of EEG signals. In 2018 IEEE\n",
      "International Conference on Pervasive Computing and Communications (PerCom) 1–10.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 33\n",
      "[42] DonoghueT,HallerM,PetersonEJ,VarmaP,SebastianP,GaoR,NotoT,LaraAH,Wal-\n",
      "lis JD, Knight RT, Shestyuk A (2020) Parameterizing neural power spectra into periodic\n",
      "and aperiodic components. Nature neuroscience 23(12):1655-1665.\n",
      "[43] Vuckovic A, Sepulveda F (2008) Delta band contribution in cue based single trial classiﬁ-\n",
      "cation of real and imaginary wrist movements. Medical biological engineering computing,\n",
      "46(6): 529-539.\n",
      "[44] Reza A, Borhani S, Sellers EW, Jiang Y, Zhao X (2019) A comprehensive review of\n",
      "EEG-based brain–computer interface paradigms. Journal of neural engineering 16 (2019):\n",
      "011001.\n",
      "[45] MalanNS,SharmaS(2019)Featureselectionusingregularizedneighbourhoodcomponent\n",
      "analysis to enhance the classiﬁcation performance of motor imagery signals. Comput Biol\n",
      "Med 107:118–126.\n",
      "[46] Shahid S, Sinha RK, Prasad G (2010) Mu and beta rhythm modulations in motor imagery\n",
      "related post-stroke EEG: a study under BCI framework for post-stroke rehabilitation.\n",
      "BMC Neurosci 11:127.\n",
      "[47] Djemal R, Bazyed AG, Belwaﬁ K, Gannouni S, Kaaniche W (2016) Three-Class EEG-\n",
      "Based Motor Imagery Classiﬁcation Using Phase-Space Reconstruction Technique. Brain\n",
      "Sci 6(3):36.\n",
      "[48] Liu YH, Lin LF, Chou CW, Chang Y, Hsiao YT, Hsu WC (2019) Analysis of Electroen-\n",
      "cephalography Event-Related Desynchronisation and Synchronisation Induced by Lower-\n",
      "Limb Stepping Motor Imagery. J Med Biol Eng 39:54–69.\n",
      "[49] Weber E, Doppelmayr M (2016) Kinesthetic motor imagery training modulates frontal\n",
      "midline theta during imagination of a dart throw. International Journal of Psychophysi-\n",
      "ology 110:137–45.\n",
      "[50] Szegedy C, Ioﬀe S, Vanhoucke V, Alemi AA (2017) Inception-v4, inception-resnet and the\n",
      "impact of residual connections on learning. Thirty-First AAAI Conference on Artiﬁcial\n",
      "Intelligence 4278–4284.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 34\n",
      "[51] Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Ra-\n",
      "binovich A (2015) Going deeper with convolutions. In Proceedings of the IEEE conference\n",
      "on computer vision and pattern recognition 1–9.\n",
      "[52] Sreeja SR, Rabha J, Nagarjuna KY, Samanta D, Mitra P, Sarma M (2017) Motor im-\n",
      "agery EEG signal processing and classiﬁcation using machine learning approach. In 2017\n",
      "International Conference on New Trends in Computing Sciences (ICTCS) 61-66.\n",
      "[53] Wang F, Zhong SH, Peng J, Jiang J, Liu Y (2018) Data augmentation for eeg-based\n",
      "emotion recognition with deep convolutional neural networks. In International Conference\n",
      "on Multimedia Modeling 82-93.\n",
      "[54] Fawzi A, Samulowitz H, Turaga D, Frossard P (2016) Adaptive data augmentation for\n",
      "image classiﬁcation. IEEE International Conference on Image Processing 3688–3692.\n",
      "[55] Lotte F (2015) Signal Processing Approaches to Minimize or Suppress Calibration\n",
      "Time in Oscillatory Activity-Based Brain Computer Interfaces. Proceedings of the IEEE\n",
      "103(6):871–90.\n",
      "[56] Guennec AL, Malinowski S, Tavenard R (2016) Data Augmentation for Time Series Clas-\n",
      "siﬁcation using Convolutional Neural Networks. ECML/PKDD Workshop on Advanced\n",
      "Analytics and Learning on Temporal Data, Sep 2016, Riva Del Garda, Italy.\n",
      "[57] Iwana BK, Uchida S (2021, January) Time series data augmentation for neural networks\n",
      "by time warping with a discriminative teacher. In 2020 25th International Conference on\n",
      "Pattern Recognition (ICPR) 3558-3565.\n",
      "[58] MNE v0.23 (2021) https://mne.tools/\n",
      "[59] PyEEG (2021) https:// Pyeeg.sourceforge.net\n",
      "[60] NeuroDSP (2021) neurodsp-tools.github.io (https://neurodsp-tools.github.io/neurodsp)\n",
      "[61] FOOOF: foof-tools.github.io/foof/(https://fooof-tools.github.io/fooof/)\n",
      "[62] Dornhege G, Milla´n JDR, Hinterberger T, McFarland D, Mu¨ller KR (2007) Toward brain-\n",
      "computer interfacing. Cambridge MA: MIT press.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 35\n",
      "[63] Li D, Zhang H, Khan MS, Mi F (2018) A self-adaptive frequency selection common spa-\n",
      "tial pattern and least squares twin support vector machine for motor imagery electroen-\n",
      "cephalography recognition. Biomed Signal Process Control 41:222–232.\n",
      "[64] Luo J, Wang J, Xu R, and Xu K (2019) Class discrepancy guided sub-band ﬁlter-based\n",
      "common spatial pattern for motor imagery classiﬁcation. J Neurosci Methods 323:98–107.\n",
      "[65] Bagh N, Reddy MR (2020) Hilbert transform-based event related patterns for motor\n",
      "imagery brain computer interface. Biomed Signal Process Control 62:102020.\n",
      "´\n",
      "[66] Alvarez-Meza AM, Vela´squez-Mart´ınez LF, Castellanos-Dominguez G (2015) Time-series\n",
      "discrimination using feature relevance analysis in motor imagery classiﬁcation. Neurocom-\n",
      "puting 151:122–129.\n",
      "[67] Kwon, O.-Y., Lee, M.-H., Guan, C., and Lee, S.-W. (2019). Subject-independent brain\n",
      "computer interfaces based on deep convolutional neural networks. IEEE transactions on\n",
      "neural networks and learning systems, 31(10):3839-3852.\n",
      "[68] Zhang, K., Robinson, N., Lee, S.-W., and Guan, C. (2021). Adaptive transfer learning\n",
      "for EEG motor imagery classiﬁcation with deep convolutional neural network. Neural\n",
      "Networks,136:1-10.\n",
      "[69] [85] Xiaowei Jia, Kang Li, Xiaoyi Li, and Aidong Zhang. 2014. A novel semi-supervised\n",
      "deep learning framework for active state recognition on eeg signals. In Bioinformatics and\n",
      "Bioengineering (BIBE), 2014 IEEE International Conference on. IEEE, 30–37.\n",
      "[70] Zhang, R., Zong, Q., Dou, L., Zhao, X., Tang, Y., and Li, Z. (2021). Hybrid deep neu-\n",
      "ral network using transfer learning for EEG motor imagery decoding. Biomedical Signal\n",
      "Processing and Control, 63:102144.\n",
      "[71] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L.\n",
      "and Polosukhin, I., 2017. Attention is all you need. In Advances in neural information\n",
      "processing systems (pp. 5998-6008).\n",
      "[72] Giulio Ruﬃni, David Ibanez, Marta Castellano, Stephen Dunne, and Aureli Soria-Frisch.\n",
      "2016. EEG-driven RNN classiﬁcation for prognosis of neurodegeneration in at-risk pa-\n",
      "tients. In International Conference on Artiﬁcial Neural Networks. Springer, 306–313.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 36\n",
      "[73] Yilu Zhao and Lianghua He. 2014. Deep learning in the EEG diagnosis of Alzheimers\n",
      "disease. In Asian Conference on Computer Vision. Springer, 340–353.\n",
      "[74] Adam Page, JT Turner, Tinoosh Mohsenin, and Tim Oates. 2014. Comparing Raw Data\n",
      "and Feature Extraction for Seizure Detection with Deep Learning Methods.. In FLAIRS\n",
      "Conference.\n",
      "[75] JT Turner, Adam Page, Tinoosh Mohsenin, and Tim Oates. 2014. Deep belief networks\n",
      "used on high resolution multichannel electroencephalography data for seizure detection.\n",
      "In 2014 AAAI Spring Symposium Series.\n",
      "[76] U Rajendra Acharya, Shu Lih Oh, Yuki Hagiwara, Jen Hong Tan, Hojjat Adeli, and\n",
      "D Puthankail Subha. 2018. Automated EEG-based screening of depression using deep\n",
      "convolutionalneuralnetwork.Computermethodsandprogramsinbiomedicine161(2018),\n",
      "103–113.\n",
      "[77] Andreas Antoniades, Loukianos Spyrou, Clive Cheong Took, and Saeid Sanei. 2016. Deep\n",
      "learning for epileptic intracranial EEG data. In Machine Learning for Signal Processing\n",
      "(MLSP), 2016 IEEE 26th International Workshop on. IEEE, 1–6.\n",
      "[78] Sergey M Plis, Devon R Hjelm, Ruslan Salakhutdinov, Elena A Allen, Henry J Bockholt,\n",
      "Je.rey D Long, Hans J Johnson, Jane S Paulsen, Jessica A Turner, and Vince D Calhoun.\n",
      "2014. Deep learning for neuroimaging: a validation study. Frontiers in neuroscience 8\n",
      "(2014), 229.\n",
      "[79] Francesco Carlo Morabito, Maurizio Campolo, Nadia Mammone, Mario Versaci, Silvana\n",
      "Francesche.i, Fabrizio Tagliavini, Vito Soﬁa, Daniela Fatuzzo, Antonio Gambardella, An-\n",
      "gelo Labate, and others. 2017. Deep learning representation from electroencephalography\n",
      "of Early-Stage Creutzfeldt-Jakob disease and features for di.erentiation from rapidly pro-\n",
      "gressive dementia. International journal of neural systems 27, 02 (2017), 1650039.\n",
      "[80] Heung-Il Suk, Chong-Yaw Wee, Seong-Whan Lee, and Dinggang Shen. 2016. State-space\n",
      "model with deep learning for functional dynamics estimation in resting-state fMRI. Neu-\n",
      "roImage 129 (2016), 292–307.\n",
      "bioRxiv preprint doi: https://doi.org/10.1101/2022.01.05.475058; this version posted February 28, 2022. The copyright holder for this preprint\n",
      "(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made \n",
      "available under aCC-BY 4.0 International license. 37\n",
      "[81] Koki Kawasaki, Tomohiro Yoshikawa, and Takeshi Furuhashi. 2015. Visualizing extracted\n",
      "feature by deep learning in P300 discrimination task. Computing and Pattern Recognition\n",
      "(SoCPaR), 2015 7th International Conference of. IEEE, 149–154.\n",
      "[82] Pouya Bashivan, Mohammed Yeasin, and Gavin M Bidelman. 2015. Single trial prediction\n",
      "of normal and excessive cognitive load through EEG feature fusion. In Signal Processing\n",
      "in Medicine and Biology Symposium (SPMB), 2015 IEEE. IEEE, 1–5.\n",
      "[83] Arunabha. M. Roy, JETP Letters 112, 173–179 (2020) DOI:\n",
      "https://doi.org/10.1134/S0021364020150023\n",
      "[84] Arunabha. M. Roy, Applied Physics A, 126, 576 (2020) DOI:\n",
      "https://doi.org/10.1007/s00339-020-03742-9\n",
      "[85] Arunabha. M. Roy, Materialia 15 (2021): 101000. DOI:\n",
      "https://doi.org/10.1016/j.mtla.2021.101000\n",
      "[86] Arunabha. M. Roy, Journal of Applied Physics 129.2 (2021): 025103. DOI:\n",
      "https://doi.org/10.1063/5.0025867\n",
      "[87] Arunabha. M. Roy, Phase ﬁeld approach for multiphase phase transformations, twinning,\n",
      "and variant-variant transformations in martensite. PhD diss., Iowa State University, 2015.\n",
      "DOI: https://doi.org/10.31274/etd-180810-4187\n",
      "[88] Arunabha. M. Roy, Physica B: Condensed Matter 615 (2021): 412986. DOI:\n",
      "https://doi.org/10.1016/j.physb.2021.412986\n",
      "[89] Arunabha. M. Roy, EPL (Europhysics Letters), 133(5), 56001. DOI:\n",
      "https://doi.org/10.1209/0295-5075/133/56001\n",
      "[90] Arunabha. M. Roy, JETP Letters 113.4 (2021): 265-272. DOI:\n",
      "https://doi.org/10.1134/S0021364021040032\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "#提取一页文字\n",
    "def extract_text_onepage (filepath,wpage):\n",
    " \n",
    "    pdf = pdfplumber.open(filepath)\n",
    "    page = pdf.pages[wpage]\n",
    "    print(page.extract_text())\n",
    " \n",
    "#提取全部文字\n",
    "def extract_text_allpage (filepath):\n",
    " \n",
    "    pdf = pdfplumber.open(filepath)\n",
    " \n",
    "    for page in pdf.pages:\n",
    "        print(page.extract_text())\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    path = os.getcwd()  #获取当前的操作目录，因为pdf文件放在了当前目录中\n",
    "    path += '\\\\a.pdf' #文件名\n",
    " \n",
    "    extract_text_onepage(path,1)\n",
    "    extract_text_allpage(path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42cea95c4a7cc38194441a937f73f8ad8a61eb030594c674f6ffb36372ba751c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML_py38_CU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
