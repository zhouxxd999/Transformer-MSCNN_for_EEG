{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import MY_bcilib as mybci\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "被试者序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train epoch \n",
    "——————————————————————————————————\n",
    "1 : 400 \n",
    "2 : 400\n",
    "3 : 400\n",
    "4 : 420 \n",
    "5 : 420\n",
    "6 : 400 \n",
    "7 : 400\n",
    "8 : 440\n",
    "9 : 400\n",
    "\n",
    "Test epoch \n",
    "——————————————————————————————————\n",
    "1 : 320\n",
    "2 : 280\n",
    "3 : 320\n",
    "4 : 320 \n",
    "5 : 320\n",
    "6 : 320 \n",
    "7 : 320\n",
    "8 : 320\n",
    "9 : 320\n",
    "\n",
    "'''\n",
    "all_epoch_num = 400  #训练集共400个epoch\n",
    "all_test_epoch_num = 320   # 共320个epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集数据与标签读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = 2.5\n",
    "time_end = 6\n",
    "time_points = 876\n",
    "train_data_r = np.zeros((all_epoch_num,3,time_points))  \n",
    "\n",
    "epo_cnt = 0\n",
    "\n",
    "for i in range(3):\n",
    "    filename = 'data/B0' + str(subject) + '0'+ str( i + 1) +'T_epo.fif'\n",
    "    epochs = mne.read_epochs(filename)\n",
    "\n",
    "    epochs_crop = epochs.crop(time_start,time_end)\n",
    "\n",
    "    data = epochs_crop.get_data()\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        train_data_r[epo_cnt,:,:] = data[i,:,:]\n",
    "        epo_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_r = np.zeros((all_epoch_num,1))\n",
    "\n",
    "cnt = 0\n",
    "for i in range(3):\n",
    "    filename = 'data/B0' + str(subject) + '0'+ str( i + 1) +'T.mat'\n",
    "    raw_label_data = loadmat(filename)\n",
    "    print( raw_label_data['classlabel'].shape)\n",
    "    train_label_r[cnt:cnt+len(raw_label_data['classlabel']),:] = raw_label_data['classlabel'] - 1 \n",
    "    cnt += len(raw_label_data['classlabel'])\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_r = train_label_r.reshape(train_label_r.shape[0],)\n",
    "\n",
    "train_label =  train_label_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_label_r shape : ',train_label_r.shape)\n",
    "print('train_data_r shape : ',train_data_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集数据与标签读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_r = np.zeros((all_test_epoch_num,3,time_points))  \n",
    "\n",
    "epo_cnt = 0\n",
    "\n",
    "for i in range(2):\n",
    "    filename = 'data/B0' + str(subject) + '0'+ str( i + 4) +'E_epo.fif'\n",
    "    epochs = mne.read_epochs(filename)\n",
    "\n",
    "    epochs_crop = epochs.crop(time_start,time_end)\n",
    "\n",
    "    data = epochs_crop.get_data()\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        test_data_r[epo_cnt,:,:] = data[i,:,:]\n",
    "        epo_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_r = np.zeros((all_test_epoch_num,1))\n",
    "\n",
    "cnt = 0\n",
    "for i in range(2):\n",
    "    filename = 'data/B0' + str(subject) + '0'+ str( i + 4) +'E.mat'\n",
    "    raw_label_data = loadmat(filename)\n",
    "    print( raw_label_data['classlabel'].shape)\n",
    "    test_label_r[cnt:cnt+len(raw_label_data['classlabel']),:] = raw_label_data['classlabel'] - 1 \n",
    "    cnt += len(raw_label_data['classlabel'])\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_r = test_label_r.reshape(test_label_r.shape[0],)\n",
    "\n",
    "test_label =  test_label_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_label_r shape : ',test_label_r.shape)\n",
    "print('test_data_r shape : ',test_data_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理，带通滤波  1-4hz   4-8hz   8-13hz   13-30hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filt = np.zeros((all_epoch_num,4,3,876))\n",
    "\n",
    "train_data_filt[:,0,:,:] = mybci.band_pass(train_data_r,1,4,sample_rate=250)\n",
    "train_data_filt[:,1,:,:] = mybci.band_pass(train_data_r,4,8,sample_rate=250)\n",
    "train_data_filt[:,2,:,:] = mybci.band_pass(train_data_r,8,13,sample_rate=250)\n",
    "train_data_filt[:,3,:,:] = mybci.band_pass(train_data_r,13,30,sample_rate=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_filt = np.zeros((all_test_epoch_num,4,3,876))\n",
    "\n",
    "test_data_filt[:,0,:,:] = mybci.band_pass(test_data_r,1,4,sample_rate=250)\n",
    "test_data_filt[:,1,:,:] = mybci.band_pass(test_data_r,4,8,sample_rate=250)\n",
    "test_data_filt[:,2,:,:] = mybci.band_pass(test_data_r,8,13,sample_rate=250)\n",
    "test_data_filt[:,3,:,:] = mybci.band_pass(test_data_r,13,30,sample_rate=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSP滤波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_W = np.zeros((4,3,3))\n",
    "\n",
    "for i in range(4):\n",
    "    csp_W[i,:,:] = mybci.cal_W(train_data_filt[train_label==0,i,:,:],train_data_filt[train_label==1,i,:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros((all_epoch_num,4,3,876))\n",
    "\n",
    "for i in range(4):\n",
    "    train_data[:,i,:,:]  = mybci.apply_mix(csp_W[i,:,:],train_data_filt[:,i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.zeros((all_test_epoch_num,4,3,876))\n",
    "\n",
    "for i in range(4):\n",
    "    test_data[:,i,:,:] = mybci.apply_mix(csp_W[i,:,:],test_data_filt[:,i,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_data shape : ,',train_data.shape)\n",
    "print('test_data shape : ,',test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_times = 10\n",
    "\n",
    "\n",
    "#-----------------------------------  left hand -----------------------------------------------------------\n",
    "train_data_left_aug = np.zeros((int(all_epoch_num * (aug_times+1) / 2 ),4,3,876))\n",
    "train_label_left_aug = np.zeros((int(all_epoch_num * (aug_times+1) / 2),4,))\n",
    "\n",
    "print(train_data_left_aug.shape)\n",
    "\n",
    "for i in range(4):\n",
    "    train_data_left_aug[:,i,:,:],train_label_left_aug[:,i,]= mybci.data_augmentation(train_data[train_label==0,i,:,:],aug_times,15,handclass='left_hand')\n",
    "\n",
    "#-----------------------------------  right hand -----------------------------------------------------------\n",
    "train_data_right_aug = np.zeros((int(all_epoch_num * (aug_times+1) / 2),4,3,876))\n",
    "train_label_right_aug = np.zeros((int(all_epoch_num * (aug_times+1) / 2),4,))\n",
    "\n",
    "print(train_data_right_aug.shape)\n",
    "\n",
    "for i in range(4):\n",
    "    train_data_right_aug[:,i,:,:],train_label_right_aug[:,i,]= mybci.data_augmentation(train_data[train_label==1,i,:,:],aug_times,15,handclass='right_hand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = np.concatenate((train_data_left_aug,train_data_right_aug))\n",
    "\n",
    "train_label_aug = np.concatenate((train_label_left_aug,train_label_right_aug))\n",
    "\n",
    "train_label_aug = train_label_aug[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_aug = train_data_aug.reshape(train_data_aug.shape[0],train_data_aug.shape[1],1,train_data_aug.shape[2],train_data_aug.shape[3])\n",
    "\n",
    "test_data = test_data.reshape(test_data.shape[0],test_data.shape[1],1,test_data.shape[2],test_data.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_data_aug shape ',train_data_aug.shape)\n",
    "\n",
    "print('train_label_aug shape ',train_label_aug.shape)\n",
    "\n",
    "print('test_data shape ',test_data.shape)\n",
    "\n",
    "print('test_label shape ',test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将标签one-hot编码，以便于后面交叉熵计算损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_aug_onehot = np.zeros((train_label_aug.shape[0],2))\n",
    "\n",
    "for i in range(train_label_aug.shape[0]):\n",
    "    if(train_label_aug[i]==0):\n",
    "        train_label_aug_onehot[i,0] = 1\n",
    "    else:\n",
    "        train_label_aug_onehot[i,1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_onehot = np.zeros((test_label.shape[0],2))\n",
    "\n",
    "for i in range(test_label.shape[0]):\n",
    "    if(test_label[i]==0):\n",
    "        test_label_onehot[i,0] = 1\n",
    "    else:\n",
    "        test_label_onehot[i,1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_label_aug_onehot shape ',train_label_aug_onehot.shape)\n",
    "print('test_label_onehot shape ',test_label_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_aug_onehot[2200:2210,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "#创建dataloader\n",
    "\n",
    "data_train_tor = torch.from_numpy(train_data_aug)\n",
    "data_train_tor = data_train_tor.float()\n",
    "print(data_train_tor.size())\n",
    "\n",
    "\n",
    "data_test_tor = torch.from_numpy(test_data)\n",
    "data_test_tor = data_test_tor.float()\n",
    "print(data_test_tor.size())\n",
    "\n",
    "\n",
    "label_train_tor = torch.from_numpy(train_label_aug_onehot)\n",
    "label_train_tor = label_train_tor.float()\n",
    "label_test_tor = torch.from_numpy(test_label_onehot)\n",
    "label_test_tor = label_test_tor.float()\n",
    "\n",
    "#改成四维张量   样本数 * 通道数 * 高 * 宽 \n",
    "#data_train_tor = data_train_tor.reshape(train_pic_data.shape[0],1,train_pic_data.shape[2],train_pic_data.shape[3])\n",
    "print(data_train_tor.size())\n",
    "\n",
    "\n",
    "#data_test_tor = data_test_tor.reshape(test_pic_data.shape[0],1,test_pic_data.shape[2],test_pic_data.shape[3])\n",
    "print(data_test_tor.size())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(data_train_tor,label_train_tor)\n",
    "test_dataset = TensorDataset(data_test_tor,label_test_tor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(train_loader):\n",
    "    X = data[0]\n",
    "    y = data[1]\n",
    "    print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建MS_CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSCNN_Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,14,(1,5),(1,1),padding=(0,2)),  #in_channel , out_channel , kernel_size , stride\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1,15),(1,15)),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(1,14,(1,3),(1,1),padding=(0,1)),  #in_channel , out_channel , kernel_size , stride\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1,15),(1,15)),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(1,14,(1,1),(1,1)),  #in_channel , out_channel , kernel_size , stride\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1,15),(1,15)),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.MaxPool2d((1,15),(1,15)),\n",
    "            nn.Conv2d(1,14,(1,1),(1,1)),  #in_channel , out_channel , kernel_size , stride\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.cl = nn.Sequential(\n",
    "            nn.Conv2d(56,112,(1,1),(1,1)),  #in_channel , out_channel , kernel_size , stride\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d((1,15),(1,15)),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(448*3*3,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32,2)\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self,img):\n",
    "        '''\n",
    "        image : 5d-array (trials x freband x channels x height x width)\n",
    "        '''\n",
    "        \n",
    "\n",
    "        feature1 = self.conv1(img[:,0,:,:,:])\n",
    "        feature2 = self.conv2(img[:,0,:,:,:])\n",
    "        feature3 = self.conv3(img[:,0,:,:,:])\n",
    "        feature4 = self.conv4(img[:,0,:,:,:])\n",
    "        \n",
    "        feature = torch.cat((feature1,feature2,feature3,feature4),dim=1)\n",
    "\n",
    "        fre1_feat = self.cl(feature)\n",
    "\n",
    "\n",
    "        feature1 = self.conv1(img[:,1,:,:,:])\n",
    "        feature2 = self.conv2(img[:,1,:,:,:])\n",
    "        feature3 = self.conv3(img[:,1,:,:,:])\n",
    "        feature4 = self.conv4(img[:,1,:,:,:])\n",
    "        \n",
    "        feature = torch.cat((feature1,feature2,feature3,feature4),dim=1)\n",
    "\n",
    "        fre2_feat = self.cl(feature)\n",
    "\n",
    "        feature1 = self.conv1(img[:,2,:,:,:])\n",
    "        feature2 = self.conv2(img[:,2,:,:,:])\n",
    "        feature3 = self.conv3(img[:,2,:,:,:])\n",
    "        feature4 = self.conv4(img[:,2,:,:,:])\n",
    "        \n",
    "        feature = torch.cat((feature1,feature2,feature3,feature4),dim=1)\n",
    "\n",
    "        fre3_feat = self.cl(feature)\n",
    "\n",
    "        feature1 = self.conv1(img[:,3,:,:,:])\n",
    "        feature2 = self.conv2(img[:,3,:,:,:])\n",
    "        feature3 = self.conv3(img[:,3,:,:,:])\n",
    "        feature4 = self.conv4(img[:,3,:,:,:])\n",
    "        \n",
    "        feature = torch.cat((feature1,feature2,feature3,feature4),dim=1)\n",
    "\n",
    "        fre4_feat = self.cl(feature)\n",
    "\n",
    "        feature_conb = torch.cat((fre1_feat,fre2_feat,fre3_feat,fre4_feat),dim=1)\n",
    "        \n",
    "        '''\n",
    "        print('img size : ',img.shape)\n",
    "        print('freband 1 feature shape: ',fre1_feat.size())\n",
    "        print('feature shape: ',feature_conb.size())\n",
    "        '''\n",
    "        output = self.fc(feature_conb.reshape(img.shape[0],-1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MSCNN_Net()\n",
    "X = torch.rand(2,4,1,3,876)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "net = MSCNN_Net()\n",
    "\n",
    "X = torch.rand(1,1,3,876)\n",
    "print(net)\n",
    "\n",
    "for name,blk in net.named_children():\n",
    "    X = blk(X)\n",
    "    print(name,'  output shape :',X.shape)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MSCNN_Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "lr,num_epochs = 0.0001,50\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "d2l.train_ch5(net,train_loader,test_loader,batch_size,optimizer,device,num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42cea95c4a7cc38194441a937f73f8ad8a61eb030594c674f6ffb36372ba751c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML_py38_CU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
